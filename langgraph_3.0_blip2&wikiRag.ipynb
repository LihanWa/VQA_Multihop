{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "# from duckduckgo_search import DDGS\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "# from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='a', description='a(obj: str) -> str - Knowledge base tool. This tool is used to provide background information from wikipedia, which the picture itself does not include the answer (such as history, the job of a person, the habits of animals).', args_schema=<class 'pydantic.v1.main.aSchema'>, func=<function a at 0x7f644fe1d5a0>),\n",
       " StructuredTool(name='b', description='b(text: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to count the text length of the text.', args_schema=<class 'pydantic.v1.main.bSchema'>, func=<function b at 0x7f644fe1cee0>),\n",
       " StructuredTool(name='c', description='c(image: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to identify the text content in the image', args_schema=<class 'pydantic.v1.main.cSchema'>, func=<function c at 0x7f645cdddc60>),\n",
       " StructuredTool(name='d', description='d(image: str) -> str - This tool should not be used on people in the image. It is used to identify a object in the image, such as a pencil, a window and so on.', args_schema=<class 'pydantic.v1.main.dSchema'>, func=<function d at 0x7f644fe1c1f0>),\n",
       " StructuredTool(name='e', description='e(image_input: str) -> str - Human face recognition. This tool is only used for human. It is used to figure out the name of the person.', args_schema=<class 'pydantic.v1.main.eSchema'>, func=<function e at 0x7f644fe45bd0>)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3me\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'human': 'What is the name of person in the image? Give me the reason.',\n",
       " 'chat_history': '',\n",
       " 'output': 'e'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol\n",
    "system_prompt = (\n",
    "    \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "    \" Use the provided tools to progress towards answering the question.\"\n",
    "    \" If you don't want to use any tools, it's OK and you should choose FINISH. And it is better than selecting useless tools.\"\n",
    ")\n",
    "# options=[\"a\",\"b\",\"c\",\"d\",\"FINISH\"]\n",
    "options=[\"a\",\"b\",\"c\",\"d\",\"e\",\"FINISH\"]\n",
    "# 'input', 'chat_history', 'intermediate_steps', 'agent_scratchpad'\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {human}\n",
    "{agent_scratchpad}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    # MessagesPlaceholder(variable_name=\"input\"),\n",
    "    # MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    # '''chat history: {chat_history}''',\n",
    "    suffix,\n",
    "    MessagesPlaceholder(variable_name=\"intermediate_steps\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    # MessagesPlaceholder(\n",
    "    #         variable_name=\"chat_history\"\n",
    "    #     ),\n",
    "    # (\"assistant\",[HumanMessage(content='Does the man in this picture do research about the cat'), 'Face_recognition_tool', FunctionMessage(content='Bruce Lee', name='Face_recognition_tool')]),\n",
    "    (\"system\",\n",
    "    # \" If you have used a tool in this task, you should not use the same tool again, because the tool will always gives the same answer for the same question.\"\n",
    "    \" If you have used a tool in this task, you should not use the same tool again.\"\n",
    "    \" So even you can't solve the promblem or can't get a satisfying answer (For example, the returned answer of tool is 'do not know, not clear'), you should not use the same tool again.\"\n",
    "    \" Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "]).partial(options=str(options))\n",
    "\n",
    "# agent = create_openai_tools_agent(llm, toool, prompt,memory)\n",
    "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
    "from langchain_openai import OpenAI\n",
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "# suffix = \"\"\"Begin!\"\n",
    "\n",
    "# {chat_history}\n",
    "# Question: {input}\n",
    "# {agent_scratchpad}\"\"\"\n",
    "\n",
    "# prompt = ZeroShotAgent.create_prompt(\n",
    "#     toool,\n",
    "#     prefix=prefix,\n",
    "#     suffix=suffix,\n",
    "#     input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    "# )\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "# llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "# agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "agent = create_openai_tools_agent(llm, toool, prompt)\n",
    "\n",
    "agent_chain = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=toool,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=False,\n",
    ")\n",
    "\n",
    "agent_chain.invoke({\"human\":\"What is the name of person in the image? Give me the reason.\"})\n",
    "# agent_chain.invoke({\"human\":\"Who tools do you have? do you have a tool that can know who a person?\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export OPENAI_API_KEY='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'\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# We will set streaming=True so that we can stream tokens\n",
    "# See the streaming section for more information on this.\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, chunk and index the contents of the blog.\n",
    "\n",
    "def search_in_rag(a):\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=(a[3][0],),\n",
    "        bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(id=\"bodyContent\")\n",
    "    ),\n",
    "    )\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "    # Retrieve and generate using the relevant snippets of the blog.\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import requests\n",
    "# from transformers import Blip2Processor, Blip2Model\n",
    "# import torch\n",
    "# from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
    "# import torch\n",
    "\n",
    "# processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-opt-6.7b\")\n",
    "# model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-6.7b\", torch_dtype=torch.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dune: part two', ['Dune: Part Two', 'Dune: Part Two (soundtrack)'], ['', ''], ['https://en.wikipedia.org/wiki/Dune:_Part_Two', 'https://en.wikipedia.org/wiki/Dune:_Part_Two_(soundtrack)']]\n",
      "Dune: Part Two\n",
      "Dune: Part Two (soundtrack)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dune: Part Two has grossed a worldwide total of $685.3 million as of April 16, 2024.'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def search_wikipedia(query):\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "    \n",
    "    PARAMS = {\n",
    "        \"action\": \"opensearch\",\n",
    "        \"search\": query,\n",
    "        \"limit\": 5,\n",
    "        \"namespace\": 0,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(URL, params=PARAMS)\n",
    "    data = response.json()\n",
    "    \n",
    "    print(data)\n",
    "    if len(data) > 1 and isinstance(data[1], list):\n",
    "        for title in data[1]:\n",
    "            print(title)\n",
    "    return data\n",
    "def search_in_rag(a):\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=(a[3][0],),\n",
    "        bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(id=\"bodyContent\")\n",
    "    ),\n",
    "    )\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "    # Retrieve and generate using the relevant snippets of the blog.\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return rag_chain\n",
    "query='Dune: part two'\n",
    "a=search_wikipedia(query)\n",
    "rag_chain=search_in_rag(a)\n",
    "ans=rag_chain.invoke(\"What is the gross of Dune: Part Two?\")\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Dune:_Part_Two'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ['Dune: part two', ['Dune: Part Two', 'Dune: Part Two (soundtrack)'], ['', ''], ['https://en.wikipedia.org/wiki/Dune:_Part_Two', 'https://en.wikipedia.org/wiki/Dune:_Part_Two_(soundtrack)']]\n",
    "# Dune: Part Two\n",
    "# Dune: Part Two (soundtrack)\n",
    "# 'The worldwide gross of movie Dune: Part Two is not explicitly stated in the provided context.'\n",
    "a[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't know.\")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#llm can't answer\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content='''You are an assistant for question-answering tasks. \n",
    "        Consider if you can answer the following question.\n",
    "        If you have 90 percent confidence about giving a correct answer, then give me the answer.\n",
    "        Otherwise, just say \"I don't know\". '''),\n",
    "        # MessagesPlaceholder(variable_name=\"context\"),\n",
    "        MessagesPlaceholder(variable_name=\"question\"),\n",
    "\n",
    "])\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol\n",
    "(prompt|llm).invoke({\"question\":[\"Does Dune: Part Two has a higher gross than Kung Fu Panda 4?\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='To determine the gross of \"Dune: Part Two\" in the image, you would need to look for information related to the movie\\'s box office earnings or revenue. This information is typically displayed in the form of a dollar amount. Look for any numbers or figures that indicate the total gross earnings for the movie \"Dune: Part Two\" in the image.'\n"
     ]
    }
   ],
   "source": [
    "#抽象问题回答\n",
    "question=\"What is the gross of Dune: Part Two?\"\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content='''You are an assistant for considering what information you want to know in the image based on the question.\n",
    "        The question is as follows:'''),\n",
    "        # MessagesPlaceholder(variable_name=\"context\"),\n",
    "        MessagesPlaceholder(variable_name=\"question\"),\n",
    "\n",
    "])\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol\n",
    "ans=(prompt|llm).invoke({\"question\":[question]})\n",
    "# ans=(prompt|llm).invoke({\"question\":[\"What is the worldwide gross of the movie Dune: part two?\"]})\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='[{\"Fish\": \"What kind of fish has a unique shape that inspired the design of kites?\"}]'\n"
     ]
    }
   ],
   "source": [
    "#entity:simple question\n",
    "question=\"What kind of fish inspired the kite design?\"\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content='''You are an assistant for splitting complex questions into simple ones. \n",
    "        Since I can only search information for just one entity each time, you should help me divide a complex quesiton into a few simple questions. \n",
    "        The answer of these simple questions should be combined to answer the complex question.\n",
    "        Make sure I only need to search for one entity for each question. Notice that this entity is small enough so that I can search it in wikipedia and get an answer.\n",
    "        The format of your returned result should be an array that contain a few dictionaries. In the dictionary, the key is the entity of the question, and the value is the simple question.\n",
    "        Here is an example:\n",
    "        Question: Is Bruce Lee older than Albert Einstein?\n",
    "        Your answer: [{{\"Bruce Lee\":\"How old is Bruce Lee\"}},{{\"Albert Einstein\":\"How old is Albert Einstein?\"}}]\n",
    "        Okay, now you should do as above. The question is as follows:'''),\n",
    "        # MessagesPlaceholder(variable_name=\"context\"),\n",
    "        MessagesPlaceholder(variable_name=\"question\"),\n",
    "\n",
    "])\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol\n",
    "ans=(prompt|llm).invoke({\"question\":[question]})\n",
    "# ans=(prompt|llm).invoke({\"question\":[\"What is the worldwide gross of the movie Dune: part two?\"]})\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#给entry更多的提示\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content='''You are an assistant for making the entity better to provide more information. \n",
    "        Currently, I'm trying to solve a complex question by dividing in to a few simple questions with their entity.\n",
    "        The entity is used to ask\n",
    "        However, some of the entity '''),\n",
    "        # MessagesPlaceholder(variable_name=\"context\"),\n",
    "        MessagesPlaceholder(variable_name=\"question\"),\n",
    "\n",
    "])\n",
    "ans=(prompt|llm).invoke({\"question\":[question]})\n",
    "# ans=(prompt|llm).invoke({\"question\":[\"What is the worldwide gross of the movie Dune: part two?\"]})\n",
    "print(\"splittted entity and questions:\\n\",ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dune: Part Two has grossed $272.1 million in the United States and Canada and $411.8 million in other territories, for a worldwide total of $683.9 million. The film is eyeing a lifetime global gross of around $700 million.'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a=search_wikipedia(\"China GDP\")\n",
    "def search_in_rag(a):\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=('https://www.bing.com/search?q=What%20is%20the%20gross%20of%20Dune%3A%20Part%20%3F&qs=n&form=QBRE&=Search%20%7B0%7D%20for%20%7B1%7D&=Search%20work%20for%20%7B0%7D&=%25eManage%20Your%20Search%20History%25E&sp=-1&lq=0&pq=what%20is%20the%20gross%20of%20dune%3A%20part%20%3F&sc=1-33&sk=&cvid=FA8DE4DD78A8425BA49627573E6110DE&ghsh=0&ghacc=0&ghpl=',),\n",
    "        bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(id=\"b_results\")\n",
    "    ),\n",
    "    )\n",
    "    docs = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "    # Retrieve and generate using the relevant snippets of the blog.\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return rag_chain\n",
    "rag_chain=search_in_rag(a)\n",
    "rag_ans=rag_chain.invoke(\"What is the gross of Dune: Part Two?\")\n",
    "rag_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['China GDP',\n",
       " ['China GDP', 'China-DPRK relations', 'China GPS offset'],\n",
       " ['', '', ''],\n",
       " ['https://en.wikipedia.org/wiki/China_GDP',\n",
       "  'https://en.wikipedia.org/wiki/China-DPRK_relations',\n",
       "  'https://en.wikipedia.org/wiki/China_GPS_offset']]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splittted entity and questions:\n",
      " content='[{\"China\":\"What is the current GDP growth rate of China?\"}]'\n",
      "entity:  China\n",
      "simple_question:  What is the current GDP growth rate of China?\n",
      "['China', ['China', 'China Airlines', 'China–India relations', 'China Central Television', 'China–United States relations'], ['', '', '', '', ''], ['https://en.wikipedia.org/wiki/China', 'https://en.wikipedia.org/wiki/China_Airlines', 'https://en.wikipedia.org/wiki/China%E2%80%93India_relations', 'https://en.wikipedia.org/wiki/China_Central_Television', 'https://en.wikipedia.org/wiki/China%E2%80%93United_States_relations']]\n",
      "China\n",
      "China Airlines\n",
      "China–India relations\n",
      "China Central Television\n",
      "China–United States relations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n",
      "[\"I don't know.\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='[{\"China\":\"What is the current GDP growth rate of China?\"}]')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=\"Does the movie Dune:Part Two has a higher gross than Kung Fu Panda 4?\"\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content='''You are an assistant for splitting complex questions into simple ones. \n",
    "        Since I can only search information for just one entity each time, you should help me divide a complex quesiton into a few simple questions. \n",
    "        The answer of these simple questions should be combined to answer the complex question.\n",
    "        Make sure I only need to search for one entity for each question. Notice that this entity should be short while concise, so I can get an answer by putting this entity into the search box of wikipedia.\n",
    "        The format of your returned result should be an array that contain a few dictionaries. In the dictionary, the key is the entity of the question, and the value is the simple question.\n",
    "        Here is an example:\n",
    "        Question: Is Bruce Lee older than Albert Einstein?\n",
    "        Your answer: [{{\"Bruce Lee\":\"How old is Bruce Lee\"}},{{\"Albert Einstein\":\"How old is Albert Einstein?\"}}]\n",
    "        Okay, now you should do as above. The question is as follows:'''),\n",
    "        # MessagesPlaceholder(variable_name=\"context\"),\n",
    "        MessagesPlaceholder(variable_name=\"question\"),\n",
    "\n",
    "])\n",
    "ans=(prompt|llm).invoke({\"question\":[question]})\n",
    "# ans=(prompt|llm).invoke({\"question\":[\"What is the worldwide gross of the movie Dune: part two?\"]})\n",
    "print(\"splittted entity and questions:\\n\",ans)\n",
    "\n",
    "import json\n",
    "back=[]\n",
    "arr=json.loads(ans.content)\n",
    "for ele in arr:\n",
    "    entity=list(ele.keys())[0]\n",
    "    simple_question=list(ele.values())[0]\n",
    "    query=entity\n",
    "    print(\"entity: \",entity)\n",
    "    print('simple_question: ',simple_question)\n",
    "    a=search_wikipedia(query)\n",
    "    rag_chain=search_in_rag(a)\n",
    "    rag_ans=rag_chain.invoke(simple_question)\n",
    "    back.append(rag_ans)\n",
    "\n",
    "#     print(rag_an)\n",
    "    \n",
    "print(back)\n",
    "rompt=ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content='''You are an assistant for answer a question based on the background inforamtion. \n",
    "        The back ground information and the question are as follows. After reading them, if you have 90 percent confidence about giving a correct answer, then give me the answer in one sentence. \n",
    "        Otherwise, just say \"I don't know\".'''),\n",
    "        'Background information:',MessagesPlaceholder(variable_name=\"background\"),\n",
    "        'Question:',MessagesPlaceholder(variable_name=\"question\"),\n",
    "\n",
    "])\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbolDoes the movie Dune: part two have a higher worldwide gross than Kung Fu Panda 4?\n",
    "(prompt|llm).invoke({\"question\":[question]\n",
    "                     ,\"background\":back})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(rag_ans==\"I don't know.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There are 27 countries in the European Union as of 2023.']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dune: Part Two\n",
      "['Dune: Part Two', ['Dune: Part Two', 'Dune: Part Two (soundtrack)'], ['', ''], ['https://en.wikipedia.org/wiki/Dune:_Part_Two', 'https://en.wikipedia.org/wiki/Dune:_Part_Two_(soundtrack)']]\n",
      "Dune: Part Two\n",
      "Dune: Part Two (soundtrack)\n",
      "Kung Fu Panda 4\n",
      "['Kung Fu Panda 4', ['Kung Fu Panda 4', 'Kung Fu Panda', 'Kung Fu Panda (film)', 'Kung Fu Panda 2', 'Kung Fu Panda 3'], ['', '', '', '', ''], ['https://en.wikipedia.org/wiki/Kung_Fu_Panda_4', 'https://en.wikipedia.org/wiki/Kung_Fu_Panda', 'https://en.wikipedia.org/wiki/Kung_Fu_Panda_(film)', 'https://en.wikipedia.org/wiki/Kung_Fu_Panda_2', 'https://en.wikipedia.org/wiki/Kung_Fu_Panda_3']]\n",
      "Kung Fu Panda 4\n",
      "Kung Fu Panda\n",
      "Kung Fu Panda (film)\n",
      "Kung Fu Panda 2\n",
      "Kung Fu Panda 3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Yes, Dune: Part Two has a higher gross than Kung Fu Panda 4.')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x7f99c83d6620> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f99c84103d0> temperature=0.0 openai_api_key=SecretStr('**********') openai_proxy=''\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.2.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# from langchain.tools import tool\n",
    "# import requests\n",
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol\n",
    "# print(llm)\n",
    "def search_wikipedia(query):\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "    \n",
    "    PARAMS = {\n",
    "        \"action\": \"opensearch\",\n",
    "        \"search\": query,\n",
    "        \"limit\": 5,\n",
    "        \"namespace\": 0,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(URL, params=PARAMS)\n",
    "    data = response.json()\n",
    "    \n",
    "    print(data)\n",
    "    if len(data) > 1 and isinstance(data[1], list):\n",
    "        for title in data[1]:\n",
    "            print(title)\n",
    "    return data\n",
    "# # @tool(\"Face_recognition_tool\", return_direct=False)\n",
    "# # def Face_recognition_tool(image_input: str) -> str:#imag 类别修改\n",
    "# #     \"\"\"This tool is only used for human. It return the name of a person by face recognition.\"\"\"\n",
    "# #     # image = Image.open(image_input).convert('RGB')   \n",
    "# #     # prompt = \"Question: who is the person? Answer:\" # Person 这个信息是从entity tool来的。\n",
    "\n",
    "# #     # inputs = processor(image, text=prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "\n",
    "# #     # generated_ids = model.generate(**inputs, max_new_tokens=10)\n",
    "# #     # generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "# #     # print(generated_text)\n",
    "\n",
    "# #     return 'Bruce Lee'\n",
    "# # @tool(\"route\",return_direct=True)\n",
    "# # def route(next):\n",
    "# #     \"Select the next role.\"\n",
    "\n",
    "\n",
    "# @tool(\"KB_tool\", return_direct=False)\n",
    "# def KB_tool(obj:str) -> str:#imag 类别修改\n",
    "#     \"\"\"This tool is only used after knowing the name of a person or a object, and this tool is used to search more information in wikipedia\"\"\"\n",
    "#     # query = obj\n",
    "    \n",
    "#     # a=search_wikipedia(query)\n",
    "#     # rag_chain=search_in_rag(a)\n",
    "#     # ans=rag_chain.invoke(\"Does Einstein do research about cat\")\n",
    "#     return 'It is not sure.'\n",
    "#     # return ans\n",
    "# @tool(\"Count_text_len_tool\", return_direct=False)\n",
    "# def Count_text_len_tool(text:str) -> int:#imag 类别修改\n",
    "#     \"\"\"This tool should not be used on human, animals or anything else except texts. It is used to count the text length of the text\"\"\"\n",
    "#     return 5\n",
    "# @tool(\"Identify_text_tool\", return_direct=False)\n",
    "# def Identify_text_tool(image:str) -> int:#imag 类别修改\n",
    "#     \"\"\"This tool should not be used on human, animals or anything else except texts. It is used to identify the text content in the image\"\"\"\n",
    "#     return 5\n",
    "# @tool(\"Identify_object_tool\", return_direct=False)\n",
    "# def Identify_object_tool(image:str) -> str:#imag 类别修改\n",
    "#     \"\"\"This tool should not be used on people in the image. It is used to identify a object in the image, such as a pencil, a window and so on.\"\"\"\n",
    "#     return \"He is Einstein.\"\n",
    "\n",
    "# # tools=[Face_recognition_tool,KB_tool,Count_text_len_tool,Identify_text_tool,Identify_object_tool]\n",
    "# tools=[KB_tool,Count_text_len_tool,Identify_text_tool,Identify_object_tool]\n",
    "# from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "# functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "# # functions = [format_tool_to_openai_function(Face_recognition_tool)]\n",
    "# llm = llm.bind_functions(functions)\n",
    "# # # print(llm)\n",
    "# from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "# tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f89321d07c0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f89321bece0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'functions': [{'name': 'KB_tool', 'description': 'KB_tool(obj: str) -> str - This tool is only used after knowing the name of a person or a object, and this tool is used to search more information in wikipedia', 'parameters': {'type': 'object', 'properties': {'obj': {'type': 'string'}}, 'required': ['obj']}}, {'name': 'Count_text_len_tool', 'description': 'Count_text_len_tool(text: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to count the text length of the text', 'parameters': {'type': 'object', 'properties': {'text': {'type': 'string'}}, 'required': ['text']}}, {'name': 'Identify_text_tool', 'description': 'Identify_text_tool(image: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to identify the text content in the image', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'Identify_object_tool', 'description': 'Identify_object_tool(image: str) -> str - This tool should not be used on human. It is used to identify a object in the image, such as a pencil, a window and so on.', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'route', 'description': 'Select the next role.', 'parameters': {'title': 'routeSchema', 'type': 'object', 'properties': {'next': {'title': 'Next', 'anyOf': [{'enum': ['FINISH', 'Face_recognition_tool', 'KB_tool', 'Count_text_len_tool', 'Identify_text_tool', 'Identify_object_tool']}]}}, 'required': ['next']}}], 'function_call': {'name': 'route'}})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x7f51705cfc40> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f517046caf0> temperature=0.0 openai_api_key=SecretStr('**********') openai_proxy=''\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.2.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol\n",
    "# # kwargs={'tools': [{'type': 'function', 'function': {'name': 'Face_recognition_tool'\n",
    "# # llm.kwargs['functions'].append({'name': 'route', 'description': 'Select the next role.', 'parameters': {'title': 'routeSchema', 'type': 'object', 'properties': {'next': {'title': 'Next', 'anyOf': [{'enum': ['FINISH', 'Face_recognition_tool', 'KB_tool', 'Count_text_len_tool', 'Identify_text_tool', 'Identify_object_tool']}]}}, 'required': ['next']}})\n",
    "# # llm.kwargs['functions'].append({'name': 'route', 'description': 'Select the next role.', 'parameters': {'title': 'routeSchema', 'type': 'object', 'properties': {'next': {'title': 'Next', 'anyOf': [{'enum': ['FINISH', 'a', 'b', 'c', 'd']}]}}, 'required': ['next']}})\n",
    "# llm.kwargs['functions'].append({'name': 'route', 'description': 'Select tools', 'parameters': {'title': 'selected tools', 'type': 'object', 'properties': {'tools': {'title': 'Tools', 'type': 'string'}}, 'required': ['tools']}})\n",
    "\n",
    "# llm.kwargs['function_call']= {'name': 'route'}\n",
    "# # print(llm.kwargs['functions'])\n",
    "\n",
    "# # for i in range(len(llm.kwargs['functions'])-1):\n",
    "# #     print(i)\n",
    "# #     if llm.kwargs['functions'][i]['name']=='Face_recognition_tool':\n",
    "# #         llm.kwargs['functions'].pop(i)\n",
    "# # for i in range(len(llm.kwargs['functions'])-1):\n",
    "# #     print(i)\n",
    "# #     if llm.kwargs['functions'][i]['name']=='KB_tool':\n",
    "# #         llm.kwargs['functions'].pop(i)\n",
    "# # # llm.kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7fb16906b3a0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7fb169069780>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='') kwargs={'functions': [{'name': 'Face_recognition_tool', 'description': 'Face_recognition_tool(image_input: str) -> str - This tool is only used for human. It return the name of a person by face recognition.', 'parameters': {'type': 'object', 'properties': {'image_input': {'type': 'string'}}, 'required': ['image_input']}}, {'name': 'KB_tool', 'description': 'KB_tool(obj: str) -> str - This tool is only used after knowing the name of a person or a object, and this tool is used to search more information in wikipedia', 'parameters': {'type': 'object', 'properties': {'obj': {'type': 'string'}}, 'required': ['obj']}}, {'name': 'Count_text_len_tool', 'description': 'Count_text_len_tool(text: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to count the text length of the text', 'parameters': {'type': 'object', 'properties': {'text': {'type': 'string'}}, 'required': ['text']}}, {'name': 'Identify_text_tool', 'description': 'Identify_text_tool(image: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to identify the text content in the image', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'Identify_object_tool', 'description': 'Identify_object_tool(image: str) -> str - This tool should not be used on human. It is used to identify a object in the image, such as a pencil, a window and so on.', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'route', 'description': 'Select the next role.', 'parameters': {'title': 'routeSchema', 'type': 'object', 'properties': {'next': {'title': 'Next', 'anyOf': [{'enum': ['FINISH', 'Face_recognition_tool', 'KB_tool', 'Count_text_len_tool', 'Identify_text_tool', 'Identify_object_tool']}]}}, 'required': ['next']}}], 'function_call': {'name': 'route'}}\n",
      "agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
      "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
      "})\n",
      "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='As an AI, you are equipped with several tools to gather insights. Read the following words carefully before making a decision.\\n    I want you to help me deal with one of the object in the image. \\n    Notice that I will use you for several times, and each time you only need to solve a small problem. You don\\'t have to care other object or people except the target currently. Your current target is: a person.\\n     You have a few options of tools to choose: Face_recognition_tool,KB_tool,Count_text_len_tool,Identify_text_tool,Identify_object_tool, FINISH. What tools do you want to use? If you think you should stop, say \"FINIFSH\".')), MessagesPlaceholder(variable_name='messages'), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
      "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7fb16906b3a0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7fb169069780>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'functions': [{'name': 'Face_recognition_tool', 'description': 'Face_recognition_tool(image_input: str) -> str - This tool is only used for human. It return the name of a person by face recognition.', 'parameters': {'type': 'object', 'properties': {'image_input': {'type': 'string'}}, 'required': ['image_input']}}, {'name': 'KB_tool', 'description': 'KB_tool(obj: str) -> str - This tool is only used after knowing the name of a person or a object, and this tool is used to search more information in wikipedia', 'parameters': {'type': 'object', 'properties': {'obj': {'type': 'string'}}, 'required': ['obj']}}, {'name': 'Count_text_len_tool', 'description': 'Count_text_len_tool(text: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to count the text length of the text', 'parameters': {'type': 'object', 'properties': {'text': {'type': 'string'}}, 'required': ['text']}}, {'name': 'Identify_text_tool', 'description': 'Identify_text_tool(image: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to identify the text content in the image', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'Identify_object_tool', 'description': 'Identify_object_tool(image: str) -> str - This tool should not be used on human. It is used to identify a object in the image, such as a pencil, a window and so on.', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'route', 'description': 'Select the next role.', 'parameters': {'title': 'routeSchema', 'type': 'object', 'properties': {'next': {'title': 'Next', 'anyOf': [{'enum': ['FINISH', 'Face_recognition_tool', 'KB_tool', 'Count_text_len_tool', 'Identify_text_tool', 'Identify_object_tool']}]}}, 'required': ['next']}}], 'function_call': {'name': 'route'}})\n",
      "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[]) tools=[StructuredTool(name='Face_recognition_tool', description='Face_recognition_tool(image_input: str) -> str - This tool is only used for human. It return the name of a person by face recognition.', args_schema=<class 'pydantic.v1.main.Face_recognition_toolSchema'>, func=<function Face_recognition_tool at 0x7fb169028af0>), StructuredTool(name='KB_tool', description='KB_tool(obj: str) -> str - This tool is only used after knowing the name of a person or a object, and this tool is used to search more information in wikipedia', args_schema=<class 'pydantic.v1.main.KB_toolSchema'>, func=<function KB_tool at 0x7fb168ea2170>), StructuredTool(name='Count_text_len_tool', description='Count_text_len_tool(text: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to count the text length of the text', args_schema=<class 'pydantic.v1.main.Count_text_len_toolSchema'>, func=<function Count_text_len_tool at 0x7fb168ea2290>), StructuredTool(name='Identify_text_tool', description='Identify_text_tool(image: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to identify the text content in the image', args_schema=<class 'pydantic.v1.main.Identify_text_toolSchema'>, func=<function Identify_text_tool at 0x7fb168ea2320>), StructuredTool(name='Identify_object_tool', description='Identify_object_tool(image: str) -> str - This tool should not be used on human. It is used to identify a object in the image, such as a pencil, a window and so on.', args_schema=<class 'pydantic.v1.main.Identify_object_toolSchema'>, func=<function Identify_object_tool at 0x7fb168ea2440>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': {'messages': [HumanMessage(content='Does the man in this picture do research about the cat'),\n",
       "   'Face_recognition_tool',\n",
       "   FunctionMessage(content='Bruce Lee', name='Face_recognition_tool')],\n",
       "  'output': ''}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain_core.messages import FunctionMessage\n",
    "# from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "# from langchain.agents.format_scratchpad.openai_tools import (\n",
    "#     format_to_openai_tool_messages,\n",
    "# )\n",
    "# from langchain_core.runnables import Runnable, RunnablePassthrough\n",
    "# from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "\n",
    "# def create_agents(llm: ChatOpenAI,\n",
    "#                   tools: list,\n",
    "#                   system_prompt: str) -> AgentExecutor:\n",
    "#     prompt = ChatPromptTemplate.from_messages([\n",
    "#         (\"system\", system_prompt),\n",
    "#         MessagesPlaceholder(variable_name=\"messages\"),\n",
    "#         MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "#     ])\n",
    "\n",
    "#     missing_vars = {\"agent_scratchpad\"}.difference(prompt.input_variables)\n",
    "#     if missing_vars:\n",
    "#         raise ValueError(f\"Prompt missing required variables: {missing_vars}\")\n",
    "\n",
    "#     # llm_with_tools = llm.bind(tools=[convert_to_openai_tool(tool) for tool in tools])\n",
    "#     print(llm)\n",
    "#     # print(llm_with_tools)\n",
    "#     agent = (\n",
    "#         RunnablePassthrough.assign(\n",
    "#             agent_scratchpad=lambda x: format_to_openai_tool_messages(\n",
    "#                 x[\"intermediate_steps\"]\n",
    "#             )\n",
    "#         )\n",
    "#         | prompt\n",
    "#         | llm\n",
    "#         | OpenAIToolsAgentOutputParser()\n",
    "#     )\n",
    "\n",
    "#     # agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "#     executor = AgentExecutor(agent=agent, tools=tools)\n",
    "#     return executor\n",
    "\n",
    "\n",
    "# news_correspondent_agent = create_agents(\n",
    "#     llm,\n",
    "#     tools,\n",
    "#     \"\"\"As an AI, you are equipped with several tools to gather insights. Read the following words carefully before making a decision.\n",
    "#     I want you to help me deal with one of the object in the image. \n",
    "#     Notice that I will use you for several times, and each time you only need to solve a small problem. You don't have to care other object or people except the target currently. Your current target is: a person.\n",
    "#      You have a few options of tools to choose: Face_recognition_tool,KB_tool,Count_text_len_tool,Identify_text_tool,Identify_object_tool, FINISH. What tools do you want to use? If you think you should stop, say \"FINIFSH\".\"\"\"\n",
    "# )\n",
    "# def agent_node(state, agent, name):\n",
    "#     print(agent)\n",
    "#     result = agent.invoke(state)\n",
    "#     return {\"messages\": result}\n",
    "#     # return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "\n",
    "\n",
    "# news_correspondent_node = functools.partial(\n",
    "#     agent_node, agent=news_correspondent_agent, name=\"news_correspondent\"\n",
    "# )\n",
    "# state={'messages': [HumanMessage(content='Does the man in this picture do research about the cat'), 'Face_recognition_tool', FunctionMessage(content='Bruce Lee', name='Face_recognition_tool')]}\n",
    "\n",
    "\n",
    "# news_correspondent_node(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "system_prompt='''As an AI, you are going to solve multi-hop VQA problems. I want to analyze a question, and provide subquestions in a list, these subquestions should be easy to answer.'''\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    # (\"assistant\",[HumanMessage(content='Does the man in this picture do research about the cat'), 'Face_recognition_tool', FunctionMessage(content='Bruce Lee', name='Face_recognition_tool')]),\n",
    "\n",
    "])\n",
    "response = openai.Completion.create(engine=\"gpt-3.5-turbo\", prompt=prompt, max_tokens=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'options': \"['a', 'b', 'c', 'd', 'FINISH']\"}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"As an AI, you are equipped with several tools to gather insights. Read the following words carefully before making a decision.\\nI want you to help me deal with one of the things in the image. It's fine if you can't solve the problem with the tool, and you should just tell me you don't know.\\nNotice that I will use you for several times, and each time you only need to solve a small problem. You don't have to care other objects or people except the target currently. Your current target is: a person.\\n\")), MessagesPlaceholder(variable_name='messages'), SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['options'], template='Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}'))])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f9a37130910>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f9a3710abf0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'functions': [{'name': 'a', 'description': 'a(obj: str) -> str - This tool is only used after knowing the name of a person or a object, and this tool is used to search more information in wikipedia', 'parameters': {'type': 'object', 'properties': {'obj': {'type': 'string'}}, 'required': ['obj']}}, {'name': 'b', 'description': 'b(text: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to count the text length of the text', 'parameters': {'type': 'object', 'properties': {'text': {'type': 'string'}}, 'required': ['text']}}, {'name': 'c', 'description': 'c(image: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to identify the text content in the image', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'd', 'description': 'd(image: str) -> str - This tool should not be used on people in the image. It is used to identify a object in the image, such as a pencil, a window and so on.', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}]})\n",
       "| JsonOutputFunctionsParser()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol\n",
    "\n",
    "# system_prompt=\"\"\"As an AI, you are equipped with several tools to gather insights. Read the following words carefully before making a decision.\n",
    "# I want you to help me deal with one of the things in the image. It's fine if you can't solve the problem with the tool, and you should just tell me you don't know.\n",
    "# Notice that I will use you for several times, and each time you only need to solve a small problem. You don't have to care other objects or people except the target currently. Your current target is: a person.\n",
    "# \"\"\"\n",
    "\n",
    "# # options=[\"Face_recognition_tool\",\"KB_tool\",\"Count_text_len_tool\",\"Identify_text_tool\",\"Identify_object_tool\",\"FINISH\"]\n",
    "# # options=[\"KB_tool\",\"Count_text_len_tool\",\"Identify_text_tool\",\"Identify_object_tool\",\"FINISH\"]\n",
    "# options=[\"a\",\"b\",\"c\",\"d\",\"FINISH\"]\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", system_prompt),\n",
    "#     MessagesPlaceholder(variable_name=\"messages\"),\n",
    "#     # (\"assistant\",[HumanMessage(content='Does the man in this picture do research about the cat'), 'Face_recognition_tool', FunctionMessage(content='Bruce Lee', name='Face_recognition_tool')]),\n",
    "#     (\"system\",\n",
    "#      \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "# ]).partial(options=str(options))\n",
    "\n",
    "# supervisor_chain = (prompt | llm | JsonOutputFunctionsParser())\n",
    "# # state={'messages': [HumanMessage(content='Does the man in this picture do research about the cat'), 'Face_recognition_tool', FunctionMessage(content='Bruce Lee', name='Face_recognition_tool')]}\n",
    "\n",
    "\n",
    "# supervisor_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x7fcaf9d0cb50> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7fcaf9c8eda0> temperature=0.0 openai_api_key=SecretStr('**********') openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "import requests\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol\n",
    "print(llm)\n",
    "def search_wikipedia(query):\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "    PARAMS = {\n",
    "        \"action\": \"opensearch\",\n",
    "        \"search\": query,\n",
    "        \"limit\": 5,\n",
    "        \"namespace\": 0,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(URL, params=PARAMS)\n",
    "    data = response.json()\n",
    "    \n",
    "    print(data)\n",
    "    if len(data) > 1 and isinstance(data[1], list):\n",
    "        for title in data[1]:\n",
    "            print(title)\n",
    "    return data\n",
    "@tool(\"e\", return_direct=False)\n",
    "def e(image_input: str) -> str:#imag 类别修改\n",
    "    \"\"\"Human face recognition. This tool is only used for human. It is used to figure out the name of the person.\"\"\"\n",
    "    # image = Image.open(image_input).convert('RGB')   \n",
    "    # prompt = \"Question: who is the person? Answer:\" # Person 这个信息是从entity tool来的。\n",
    "\n",
    "    # inputs = processor(image, text=prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "\n",
    "    # generated_ids = model.generate(**inputs, max_new_tokens=10)\n",
    "    # generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "    # print(generated_text)\n",
    "\n",
    "    return \"We don't know.\"\n",
    "# @tool(\"route\",return_direct=True)\n",
    "# def route(next):\n",
    "#     \"Select the next role.\"\n",
    "\n",
    "\n",
    "@tool(\"a\", return_direct=False)\n",
    "def a(obj:str) -> str:#imag 类别修改\n",
    "    \"\"\"Knowledge base tool. This tool is used to provide background information from wikipedia, which the picture itself does not include the answer (such as history, the job of a person, the habits of animals).\"\"\"\n",
    "    # query = obj\n",
    "    \n",
    "    # a=search_wikipedia(query)\n",
    "    # rag_chain=search_in_rag(a)\n",
    "    # ans=rag_chain.invoke(\"Does Einstein do research about cat\")\n",
    "    return \"I can't give a good answer.\"\n",
    "    # return ans\n",
    "@tool(\"b\", return_direct=False)\n",
    "def b(text:str) -> int:#imag 类别修改\n",
    "    \"\"\"This tool should not be used on human, animals or anything else except texts. It is used to count the text length of the text.\"\"\"\n",
    "    return \"I can't give a good answer.\"\n",
    "@tool(\"c\", return_direct=False)\n",
    "def c(image:str) -> int:#imag 类别修改\n",
    "    \"\"\"This tool should not be used on human, animals or anything else except texts. It is used to identify the text content in the image\"\"\"\n",
    "    return 5\n",
    "@tool(\"d\", return_direct=False)\n",
    "def d(image:str) -> str:#imag 类别修改\n",
    "    \"\"\"This tool should not be used on people in the image. It is used to identify a object in the image, such as a pencil, a window and so on.\"\"\"\n",
    "    return \"We don't know.\"\n",
    "\n",
    "# tools=[Face_recognition_tool,KB_tool,Count_text_len_tool,Identify_text_tool,Identify_object_tool]\n",
    "tools=[a,b,c,d,e]\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "# functions = [format_tool_to_openai_function(Face_recognition_tool)]\n",
    "llm = llm.bind_functions(functions)\n",
    "# # print(llm)\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import FunctionMessage\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "import ast\n",
    "import json\n",
    "def call_Face_recognition_tool(state):\n",
    "    action = ToolInvocation(\n",
    "        tool='e',\n",
    "        # tool_input=json.loads('{\"image_input\":\"/root/projects/Einstein2.png\"}'),\n",
    "        tool_input=json.loads('{\"image_input\":\"a.png\"}'),\n",
    "    )\n",
    "    response = tool_executor.invoke(action)#函数返回值\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"Tool_return\": [function_message]}\n",
    "\n",
    "\n",
    "def call_KB_tool(state):\n",
    "    action = ToolInvocation(\n",
    "        tool='a',\n",
    "        # tool_input=json.loads('{\"obj\":\"Einstein\"}'),\n",
    "        tool_input=json.loads('{\"obj\":\"bilibili\"}'),\n",
    "    )\n",
    "    response = tool_executor.invoke(action)#函数返回值\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"Tool_return\": [function_message]}\n",
    "    # return {\"messages\": [function_message]}\n",
    "def call_Count_text_len_tool(state):\n",
    "    action = ToolInvocation(\n",
    "        tool='b',\n",
    "        tool_input=json.loads('{\"text\":\"balala\"}'),\n",
    "    )\n",
    "    response = tool_executor.invoke(action)#函数返回值\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"Tool_return\": [function_message]}\n",
    "def call_Identify_text_tool(state):\n",
    "    action = ToolInvocation(\n",
    "        tool='c',\n",
    "        tool_input=json.loads('{\"image\":\"adfs.png\"}'),\n",
    "    )\n",
    "    response = tool_executor.invoke(action)#函数返回值\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"Tool_return\": [function_message]}\n",
    "def call_Identify_object_tool(state):\n",
    "    action = ToolInvocation(\n",
    "        tool='d',\n",
    "        tool_input=json.loads('{\"image\":\"ok.png\"}'),\n",
    "    )\n",
    "    response = tool_executor.invoke(action)#函数返回值\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"Tool_return\": [function_message]}\n",
    "# def call_Agent(state):\n",
    "#     system_prompt = (\n",
    "#         \"As an AI, you are equipped with several tools to gather insights. Question: Does the person in the image do research about the cat? \"\n",
    "#         # \"Determine what tool you want to use next. \"\n",
    "#         \"The tools should be used to know more information about the person in the image. \"\n",
    "#         # # \"Don't use 'Face_recognition_tool', which have been used.\"\n",
    "#         # \"'Face_recognition_tool'  and 'KB_tool' have been used. And don't use them again.\"\n",
    "\n",
    "#         \"If you think  tools are not really useful: choose 'FINISH'. \"\n",
    "#         \"Else:  select other tools. After selecting the appropriate tools, briefly explain the rationale behind your choice. \"\n",
    "#         # \"Given the conversation above, which tools do you want to use?\"\n",
    "\n",
    "\n",
    "#     )\n",
    "toool=[a,b,c,d,e]\n",
    "print(type(tool))\n",
    "# def call_Agent(input):\n",
    "#     system_prompt = (\n",
    "#         \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "#         \" Use the provided tools to progress towards answering the question.\"\n",
    "#         \" If you don't want to use any tools, it's OK and you should choose FINISH. And it is better than selecting useless tools.\"\n",
    "#     )\n",
    "#     options=[\"a\",\"b\",\"c\",\"d\",\"FINISH\"]\n",
    "\n",
    "#     prompt = ChatPromptTemplate.from_messages([\n",
    "#         (\"system\", system_prompt),\n",
    "#         MessagesPlaceholder(variable_name=\"messages\"),\n",
    "#         # (\"assistant\",[HumanMessage(content='Does the man in this picture do research about the cat'), 'Face_recognition_tool', FunctionMessage(content='Bruce Lee', name='Face_recognition_tool')]),\n",
    "#         (\"system\",\n",
    "#         \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "#     ]).partial(options=str(options))\n",
    "#     # 假设这是你的链式操作\n",
    "    # supervisor_chain = (prompt | llm | JsonOutputFunctionsParser())\n",
    "\n",
    "    # # 定义一个封装这个链式操作的函数\n",
    "    # def supervisor_chain_function(input_data):\n",
    "    # # 使用 run 方法执行链式操作\n",
    "    #     return supervisor_chain.run(input_data)\n",
    "\n",
    "\n",
    "    # # 使用这个函数获取结果\n",
    "    # result = supervisor_chain_function(input)\n",
    "\n",
    "    # import json\n",
    "    # tool=json.loads(result.additional_kwargs['function_call']['arguments'])['tools']\n",
    "    # tool=tool.split(\",\")\n",
    "    # print(tool)\n",
    "    # # type(tool)\n",
    "\n",
    "    # global loader\n",
    "    # loader=memory_loader(tool)\n",
    "    # return {\"messages\":tool}\n",
    "# def create_agents(llm: ChatOpenAI,\n",
    "#                   tools: list,\n",
    "#                   system_prompt: str) -> AgentExecutor:\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol\n",
    "system_prompt = (\n",
    "    \"You are a helpful AI assistant, and you should mainly depend on the Question, Previously used tools and The corresponded return value of the tools to make decisions.\"\n",
    "    \" Use the provided tools to progress towards answering the question.\"\n",
    "    \" If you don't want to use any tools, it's OK and you should choose FINISH. And it is better than selecting useless tools.\"\n",
    ")\n",
    "# options=[\"a\",\"b\",\"c\",\"d\",\"FINISH\"]\n",
    "options=[\"a\",\"b\",\"c\",\"d\",\"e\",\"FINISH\"]\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"Question\"),\n",
    "    MessagesPlaceholder(variable_name=\"Previously used tools and The corresponded return value of the tools\"),\n",
    "    # MessagesPlaceholder(variable_name=\"Question\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    # MessagesPlaceholder(\n",
    "    #         variable_name=\"chat_history\"\n",
    "    #     ),\n",
    "    # (\"assistant\",[HumanMessage(content='Does the man in this picture do research about the cat'), 'Face_recognition_tool', FunctionMessage(content='Bruce Lee', name='Face_recognition_tool')]),\n",
    "    (\"system\",\n",
    "    # \" If you have used a tool in this task, you should not use the same tool again, because the tool will always gives the same answer for the same question.\"\n",
    "    \" If you have used a tool in this task, you should not use the same tool again.\"\n",
    "    \" So even you can't solve the promblem or can't get a satisfying answer (For example, the returned answer of tool is 'do not know, not clear'), you should not use the same tool again.\"\n",
    "    \" Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "]).partial(options=str(options))\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "print(type(tool))\n",
    "agent = create_openai_tools_agent(llm, toool, prompt)\n",
    "# executor = AgentExecutor(agent=agent, tools=toool,memory=memory,verbose=True)\n",
    "executor = AgentExecutor(agent=agent, tools=toool)\n",
    "def create_agents(state):\n",
    "    if('next' in state): state.pop('next')\n",
    "    print('state',state)\n",
    "    new_state = {\n",
    "        'Question': [],\n",
    "        'Previously used tools and The corresponded return value of the tools': []\n",
    "    }\n",
    "    new_state['Question'].append(f\"Question: {state['Question'][0]}\")\n",
    "    if 'Tool_return' in state and state['Tool_return'] is not None:\n",
    "        for tool_return in state['Tool_return']:\n",
    "            new_state['Previously used tools and The corresponded return value of the tools'].append(\n",
    "                f\"Previously used tool: {tool_return.name}. The corresponded return value of the tools: {tool_return.content}\"\n",
    "            )\n",
    "    # print(new_state)\n",
    "    print('new state:',new_state)\n",
    "    res=executor.invoke(new_state)\n",
    "    # res=executor.invoke(state)\n",
    "    print(res)\n",
    "    return {\"next\":res['output']}\n",
    "def memory_loader(l):\n",
    "\n",
    "    memory=l\n",
    "    i=0\n",
    "    def load_memory():\n",
    "        \n",
    "        nonlocal i\n",
    "        if i==len(l): return 'FINISH'\n",
    "        res=memory[i]\n",
    "        i+=1\n",
    "        return res\n",
    "    return load_memory\n",
    "\n",
    "def Call_Arranger(input):\n",
    "    \n",
    "\n",
    "        \n",
    "    option=loader()\n",
    "    return {\"next\": option}\n",
    "# def memory_loader():\n",
    "\n",
    "#     memory=[]\n",
    "#     def load_memory(new_msg):\n",
    "        \n",
    "        \n",
    "#         memory.append(new_msg)\n",
    "#         return memory\n",
    "#     return load_memory\n",
    "# loader = memory_loader()\n",
    "# def Call_Data_collecter(state):\n",
    "#     print(MessagesPlaceholder(variable_name=\"messages\"))\n",
    "#     curtool=state['next']\n",
    "#     tool_used=loader(curtool)\n",
    "#     return {\"messages\": tool_used}\n",
    "print(type(tool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Question': ['Question: content=\"What is Bruce Lee\\'s job? \"'], 'Previously used tools and The corresponded return value of the tools': [\"Previously used tool: a. The corresponded return value of the tools: I can't give a good answer.\"], 'output': 'FINISH'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'next': 'FINISH'}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state={'Question': [HumanMessage(content=\"What is Bruce Lee's job? \")], 'Tool_return': [FunctionMessage(content=\"I can't give a good answer, AI assistant should not choose 'b' tool again.\", name='b'), FunctionMessage(content=\"It's Lee.\", name='a')]}\n",
    "# # state={\"Question\": [\"Question: What is Bruce Lee's job?\"] ,\"Previously used tools and The corresponded return value of the tools\":[\"Previously used tool: b. The corresponded return value of the tools: I can't give a good answer, AI assistant should not choose 'b' tool again.\",\"Previously used tool: a. The corresponded return value of the tools: It's Lee.\"]}\n",
    "# # state={\"Question\": [\"Question: What is Bruce Lee's job?\"] }\n",
    "# new_state = {\n",
    "#     'Question': [],\n",
    "#     'Previously used tools and The corresponded return value of the tools': []\n",
    "# }\n",
    "\n",
    "\n",
    "# # # 提取 Question\n",
    "# # print(f\"Question: {state['Question'][0]}\")\n",
    "# new_state['Question'].append(f\"Question: {state['Question'][0]}\")\n",
    "\n",
    "# # print(state['Tool_return'][0])\n",
    "# # 提取 Tool_return 并格式化\n",
    "# for tool_return in state['Tool_return']:\n",
    "#     new_state['Previously used tools and The corresponded return value of the tools'].append(\n",
    "#         f\"Previously used tool: {tool_return.name}. The corresponded return value of the tools: {tool_return.content}\"\n",
    "#     )\n",
    "# print(new_state)\n",
    "def create_agents(state):\n",
    "    if('next' in state): state.pop('next')\n",
    "    res=executor.invoke(new_state)\n",
    "    # res=executor.invoke(state)\n",
    "    print(res)\n",
    "    return {\"next\":res['output']}\n",
    "new_state={'Question': ['Question: content=\"What is Bruce Lee\\'s job? \"'], 'Previously used tools and The corresponded return value of the tools': [\"Previously used tool: a. The corresponded return value of the tools: I can't give a good answer.\"]}\n",
    "\n",
    "create_agents(new_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'Question': ['Question: Question: content=\"What is Bruce Lee\\'s job? \"'], 'Previously used tools and The corresponded return value of the tools': []}\n",
    "{'Question': ['Question: content=\"What is Bruce Lee\\'s job? \"'], 'Previously used tools and The corresponded return value of the tools': [\"Previously used tool: a. The corresponded return value of the tools: I can't give a good answer, AI assistant should not choose 'a' tool again.\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol\n",
    "# system_prompt = (\n",
    "#     \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "#     \" Use the provided tools to progress towards answering the question.\"\n",
    "#     \" If you don't want to use any tools, it's OK and you should choose FINISH. And it is better than selecting useless tools.\"\n",
    "# )\n",
    "\n",
    "# options=[\"a\",\"b\",\"c\",\"d\",\"e\",\"FINISH\"]\n",
    "# suffix = \"\"\"\n",
    "# {chat_history}\n",
    "# Question: {human}\"\"\"\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", system_prompt),\n",
    "#     suffix,\n",
    "#     MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "#     MessagesPlaceholder(variable_name=\"intermediate_steps\"),\n",
    "#     MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "#     (\"system\",\n",
    "#     \" If you have used a tool in this task, you should not use the same tool again.\"\n",
    "#     \" So even you can't solve the promblem or can't get a satisfying answer (For example, the returned answer of tool is 'do not know, not clear'), you should not use the same tool again.\"\n",
    "#     \" Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "# ]).partial(options=str(options))\n",
    "# memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "# # llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "# # agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "# agent = create_openai_tools_agent(llm, toool, prompt)\n",
    "\n",
    "# agent_executor = AgentExecutor(\n",
    "#     agent=agent,\n",
    "#     tools=toool,\n",
    "#     memory=memory,\n",
    "#     verbose=True,\n",
    "#     return_intermediate_steps=False,\n",
    "# )\n",
    "# # res=agent_executor.invoke({\"human\":'What is the age of the man in the image? Give me the reason. '})\n",
    "# # print(res)\n",
    "# import pdb\n",
    "# def create_agents(state):\n",
    "#     print(type(state))\n",
    "#     # pdb.set_trace()\n",
    "#     res=agent_executor.invoke({\"human\":'What is the age of the man in the image? Give me the reason. '})\n",
    "#     print(res)\n",
    "#     return {\"next\":res['output']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 'b', 'a': 'a', 'c': 'c', 'd': 'd', 'e': 'e', 'FINISH': '__end__'}\n",
      "state {'Question': [HumanMessage(content='Is Bruce Lee older than Albert Einstein?')], 'Tool_return': None}\n",
      "new state: {'Question': [\"Question: content='Is Bruce Lee older than Albert Einstein?'\"], 'Previously used tools and The corresponded return value of the tools': []}\n",
      "{'Question': [\"Question: content='Is Bruce Lee older than Albert Einstein?'\"], 'Previously used tools and The corresponded return value of the tools': [], 'output': 'a'}\n",
      "{'agent': {'next': 'a'}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "{'a': {'Tool_return': [FunctionMessage(content=\"I can't give a good answer.\", name='a')]}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "state {'Question': [HumanMessage(content='Is Bruce Lee older than Albert Einstein?')], 'Tool_return': [FunctionMessage(content=\"I can't give a good answer.\", name='a')]}\n",
      "new state: {'Question': [\"Question: content='Is Bruce Lee older than Albert Einstein?'\"], 'Previously used tools and The corresponded return value of the tools': [\"Previously used tool: a. The corresponded return value of the tools: I can't give a good answer.\"]}\n",
      "{'Question': [\"Question: content='Is Bruce Lee older than Albert Einstein?'\"], 'Previously used tools and The corresponded return value of the tools': [\"Previously used tool: a. The corresponded return value of the tools: I can't give a good answer.\"], 'output': 'FINISH'}\n",
      "{'agent': {'next': 'FINISH'}}\n",
      "\n",
      "-----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# import ipydb\n",
    "# Define a new graph\n",
    "# tools=[\"Count_text_len_tool\",\"Face_recognition_tool\",\"KB_tool\",\"Identify_text_tool\",\"Identify_object_tool\"]\n",
    "tools=[\"b\",\"a\",\"c\",\"d\",\"e\"]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    Question: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # Tool_return:Sequence[BaseMessage]\n",
    "    Tool_return:Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "    # human: str\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", create_agents)#不确定应该call_model还是用chain，这里先尝试chain\n",
    "# workflow.add_node(\"data_collecter\", Call_Data_collecter)#不确定应该call_model还是用chain，这里先尝试chain\n",
    "workflow.add_node(\"e\", call_Face_recognition_tool)\n",
    "# workflow.add_node(\"arranger\",Call_Arranger)\n",
    "workflow.add_node(\"a\", call_KB_tool)\n",
    "workflow.add_node(\"b\", call_Count_text_len_tool)\n",
    "workflow.add_node(\"c\", call_Identify_text_tool)\n",
    "workflow.add_node(\"d\", call_Identify_object_tool)\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "conditional_map = {k: k for k in tools}\n",
    "conditional_map['FINISH'] = END\n",
    "print(conditional_map)\n",
    "# workflow.add_edge(\"agent\",\"arranger\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\", lambda x: x[\"next\"], conditional_map)\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"arranger\", lambda x: x[\"next\"], conditional_map)\n",
    "\n",
    "for tool in tools:\n",
    "    workflow.add_edge(start_key=tool, end_key=\"agent\")\n",
    "# for tool in tools:\n",
    "#     workflow.add_edge(start_key=tool, end_key=\"arranger\")\n",
    "\n",
    "\n",
    "graph = workflow.compile()\n",
    "for s in graph.stream(\n",
    "\n",
    "    {\"Question\": [HumanMessage(content=\"Is Bruce Lee older than Albert Einstein?\")]}, #要有问题，否则不会停\n",
    "    # {\"human\": \"What is the age of the man in the image? Give me the reason. \"}, #要有问题，否则不会停\n",
    "    # {\"human\": \"\"}, #要有问题，否则不会停\n",
    "\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 150}\n",
    "):\n",
    "    if not \"__end__\" in s:\n",
    "        # print((llm))\n",
    "        print(s, end=\"\\n\\n-----------------\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'supervisor_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m workflow \u001b[38;5;241m=\u001b[39m StateGraph(AgentState)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Define the two nodes we will cycle between\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m workflow\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43msupervisor_chain\u001b[49m)\u001b[38;5;66;03m#不确定应该call_model还是用chain，这里先尝试chain\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# workflow.add_node(\"data_collecter\", Call_Data_collecter)#不确定应该call_model还是用chain，这里先尝试chain\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# workflow.add_node(\"Face_recognition_tool\", call_Face_recognition_tool)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m workflow\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKB_tool\u001b[39m\u001b[38;5;124m\"\u001b[39m, call_KB_tool)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'supervisor_chain' is not defined"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# import ipydb\n",
    "# Define a new graph\n",
    "# tools=[\"Count_text_len_tool\",\"Face_recognition_tool\",\"KB_tool\",\"Identify_text_tool\",\"Identify_object_tool\"]\n",
    "tools=[\"Count_text_len_tool\",\"KB_tool\",\"Identify_text_tool\",\"Identify_object_tool\"]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", supervisor_chain)#不确定应该call_model还是用chain，这里先尝试chain\n",
    "# workflow.add_node(\"data_collecter\", Call_Data_collecter)#不确定应该call_model还是用chain，这里先尝试chain\n",
    "# workflow.add_node(\"Face_recognition_tool\", call_Face_recognition_tool)\n",
    "workflow.add_node(\"KB_tool\", call_KB_tool)\n",
    "workflow.add_node(\"Count_text_len_tool\", call_Count_text_len_tool)\n",
    "workflow.add_node(\"Identify_text_tool\", call_Identify_text_tool)\n",
    "workflow.add_node(\"Identify_object_tool\", call_Identify_object_tool)\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "conditional_map = {k: k for k in tools}\n",
    "conditional_map['FINISH'] = END\n",
    "print(conditional_map)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\", lambda x: x[\"next\"], conditional_map)\n",
    "\n",
    "for tool in tools:\n",
    "    workflow.add_edge(start_key=tool, end_key=\"agent\")\n",
    "\n",
    "\n",
    "graph = workflow.compile()\n",
    "for s in graph.stream(\n",
    "\n",
    "    {\"messages\": [HumanMessage(content=\"Is this man Bruce Lee?\")]}, #要有问题，否则不会停\n",
    "\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 150}\n",
    "):\n",
    "    if not \"__end__\" in s:\n",
    "        print((llm))\n",
    "        print(s, end=\"\\n\\n-----------------\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import FunctionMessage\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "import ast\n",
    "import json\n",
    "# def call_Face_recognition_tool(state):\n",
    "#     action = ToolInvocation(\n",
    "#         tool='Face_recognition_tool',\n",
    "#         # tool_input=json.loads('{\"image_input\":\"/root/projects/Einstein2.png\"}'),\n",
    "#         tool_input=json.loads('{\"image_input\":\"a.png\"}'),\n",
    "#     )\n",
    "#     response = tool_executor.invoke(action)#函数返回值\n",
    "#     function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "#     return {\"messages\": [function_message]}\n",
    "def call_KB_tool(state):\n",
    "    action = ToolInvocation(\n",
    "        tool='KB_tool',\n",
    "        # tool_input=json.loads('{\"obj\":\"Einstein\"}'),\n",
    "        tool_input=json.loads('{\"obj\":\"bilibili\"}'),\n",
    "    )\n",
    "    response = tool_executor.invoke(action)#函数返回值\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"messages\": [function_message]}\n",
    "def call_Count_text_len_tool(state):\n",
    "    action = ToolInvocation(\n",
    "        tool='Text_Len_tool',\n",
    "        tool_input=json.loads('{\"text\":\"balala\"}'),\n",
    "    )\n",
    "    response = tool_executor.invoke(action)#函数返回值\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"messages\": [function_message]}\n",
    "def call_Identify_text_tool(state):\n",
    "    action = ToolInvocation(\n",
    "        tool='Identify_text_tool',\n",
    "        tool_input=json.loads('{\"image\":\"adfs.png\"}'),\n",
    "    )\n",
    "    response = tool_executor.invoke(action)#函数返回值\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"messages\": [function_message]}\n",
    "def call_Identify_object_tool(state):\n",
    "    action = ToolInvocation(\n",
    "        tool='Identify_object_tool',\n",
    "        tool_input=json.loads('{\"image\":\"ok.png\"}'),\n",
    "    )\n",
    "    response = tool_executor.invoke(action)#函数返回值\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"messages\": [function_message]}\n",
    "# def call_Agent(state):\n",
    "#     system_prompt = (\n",
    "#         \"As an AI, you are equipped with several tools to gather insights. Question: Does the person in the image do research about the cat? \"\n",
    "#         # \"Determine what tool you want to use next. \"\n",
    "#         \"The tools should be used to know more information about the person in the image. \"\n",
    "#         # # \"Don't use 'Face_recognition_tool', which have been used.\"\n",
    "#         # \"'Face_recognition_tool'  and 'KB_tool' have been used. And don't use them again.\"\n",
    "\n",
    "#         \"If you think  tools are not really useful: choose 'FINISH'. \"\n",
    "#         \"Else:  select other tools. After selecting the appropriate tools, briefly explain the rationale behind your choice. \"\n",
    "#         # \"Given the conversation above, which tools do you want to use?\"\n",
    "\n",
    "\n",
    "#     )\n",
    "def call_Agent(input):\n",
    "    system_prompt = (\n",
    "        \"As an AI, you are equipped with several tools to gather insights. Question: Does the person in the image do research about the cat? \"\n",
    "        # \"Determine what tool you want to use next. \"\n",
    "        \"The tools should be used to know more information about the cat in the image. \"\n",
    "        # # \"Don't use 'Face_recognition_tool', which have been used.\"\n",
    "        # \"'Face_recognition_tool'  and 'KB_tool' have been used. And don't use them again.\"\n",
    "\n",
    "        \"If you think  tools are not really useful: choose 'FINISH'. \"\n",
    "        \"Else:  select other tools. After selecting the appropriate tools, briefly explain the rationale behind your choice. \"\n",
    "        # \"Given the conversation above, which tools do you want to use?\"\n",
    "\n",
    "\n",
    "    )\n",
    "\n",
    "    a=llm.invoke(system_prompt)\n",
    "    import json\n",
    "    tool=json.loads(a.additional_kwargs['function_call']['arguments'])['tools']\n",
    "    tool=tool.split(\",\")\n",
    "    # type(tool)\n",
    "\n",
    "    global loader\n",
    "    loader=memory_loader(tool)\n",
    "    return {\"messages\":tool}\n",
    "def memory_loader(l):\n",
    "\n",
    "    memory=l\n",
    "    i=0\n",
    "    def load_memory():\n",
    "        \n",
    "        nonlocal i\n",
    "        if i==len(l): return 'FINISH'\n",
    "        res=memory[i]\n",
    "        i+=1\n",
    "        return res\n",
    "    return load_memory\n",
    "\n",
    "def Call_Arranger(input):\n",
    "    \n",
    "\n",
    "        \n",
    "    option=loader()\n",
    "    return {\"next\": option}\n",
    "# def memory_loader():\n",
    "\n",
    "#     memory=[]\n",
    "#     def load_memory(new_msg):\n",
    "        \n",
    "        \n",
    "#         memory.append(new_msg)\n",
    "#         return memory\n",
    "#     return load_memory\n",
    "# loader = memory_loader()\n",
    "# def Call_Data_collecter(state):\n",
    "#     print(MessagesPlaceholder(variable_name=\"messages\"))\n",
    "#     curtool=state['next']\n",
    "#     tool_used=loader(curtool)\n",
    "#     return {\"messages\": tool_used}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kwargs={'tools': [{'type': 'function', 'function': {'name': 'Face_recognition_tool', 'description': 'Face_recognition_tool(image_input: str) -> str - This tool is only used for human. It return the name of a person by face recognition.', 'parameters': {'type': 'object', 'properties': {'image_input': {'type': 'string'}}, 'required': ['image_input']}}}, {'type': 'function', 'function': {'name': 'KB_tool', 'description': 'KB_tool(obj: str) -> str - This tool is only used after knowing the name of a person or a object, and this tool is used to search more information in wikipedia', 'parameters': {'type': 'object', 'properties': {'obj': {'type': 'string'}}, 'required': ['obj']}}}, {'type': 'function', 'function': {'name': 'Count_text_len_tool', 'description': 'Count_text_len_tool(text: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to count the text length of the text', 'parameters': {'type': 'object', 'properties': {'text': {'type': 'string'}}, 'required': ['text']}}}, {'type': 'function', 'function': {'name': 'Identify_text_tool', 'description': 'Identify_text_tool(image: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to identify the text content in the image', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}}, {'type': 'function', 'function': {'name': 'Identify_object_tool', 'description': 'Identify_object_tool(image: str) -> str - This tool should not be used on human. It is used to identify a object in the image, such as a pencil, a window and so on.', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}}]}\n",
    "\n",
    "kwargs={'functions': [{'name': 'Face_recognition_tool', 'description': 'Face_recognition_tool(image_input: str) -> str - This tool is only used for human. It return the name of a person by face recognition.', 'parameters': {'type': 'object', 'properties': {'image_input': {'type': 'string'}}, 'required': ['image_input']}}, {'name': 'KB_tool', 'description': 'KB_tool(obj: str) -> str - This tool is only used after knowing the name of a person or a object, and this tool is used to search more information in wikipedia', 'parameters': {'type': 'object', 'properties': {'obj': {'type': 'string'}}, 'required': ['obj']}}, {'name': 'Count_text_len_tool', 'description': 'Count_text_len_tool(text: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to count the text length of the text', 'parameters': {'type': 'object', 'properties': {'text': {'type': 'string'}}, 'required': ['text']}}, {'name': 'Identify_text_tool', 'description': 'Identify_text_tool(image: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to identify the text content in the image', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'Identify_object_tool', 'description': 'Identify_object_tool(image: str) -> str - This tool should not be used on human. It is used to identify a object in the image, such as a pencil, a window and so on.', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}]})\n",
    "\n",
    "kwargs={'functions': [{'name': 'Face_recognition_tool', 'description': 'Face_recognition_tool(image_input: str) -> str - This tool is only used for human. It return the name of a person by face recognition.', 'parameters': {'type': 'object', 'properties': {'image_input': {'type': 'string'}}, 'required': ['image_input']}}, {'name': 'KB_tool', 'description': 'KB_tool(obj: str) -> str - This tool is only used after knowing the name of a person or a object, and this tool is used to search more information in wikipedia', 'parameters': {'type': 'object', 'properties': {'obj': {'type': 'string'}}, 'required': ['obj']}}, {'name': 'Count_text_len_tool', 'description': 'Count_text_len_tool(text: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to count the text length of the text', 'parameters': {'type': 'object', 'properties': {'text': {'type': 'string'}}, 'required': ['text']}}, {'name': 'Identify_text_tool', 'description': 'Identify_text_tool(image: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to identify the text content in the image', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'Identify_object_tool', 'description': 'Identify_object_tool(image: str) -> str - This tool should not be used on human. It is used to identify a object in the image, such as a pencil, a window and so on.', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'route', 'description': 'Select the next role.', 'parameters': {'title': 'routeSchema', 'type': 'object', 'properties': {'next': {'title': 'Next', 'anyOf': [{'enum': ['FINISH', 'Face_recognition_tool', 'KB_tool', 'Count_text_len_tool', 'Identify_text_tool', 'Identify_object_tool']}]}}, 'required': ['next']}}], 'function_call': {'name': 'route'}})\n",
    "\n",
    "bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f006eb4be20>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f006eb48910>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='') kwargs={'functions': [{'name': 'Face_recognition_tool', 'description': 'Face_recognition_tool(image_input: str) -> str - This tool is only used for human. It return the name of a person by face recognition.', 'parameters': {'type': 'object', 'properties': {'image_input': {'type': 'string'}}, 'required': ['image_input']}}, {'name': 'KB_tool', 'description': 'KB_tool(obj: str) -> str - This tool is only used after knowing the name of a person or a object, and this tool is used to search more information in wikipedia', 'parameters': {'type': 'object', 'properties': {'obj': {'type': 'string'}}, 'required': ['obj']}}, {'name': 'Count_text_len_tool', 'description': 'Count_text_len_tool(text: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to count the text length of the text', 'parameters': {'type': 'object', 'properties': {'text': {'type': 'string'}}, 'required': ['text']}}, {'name': 'Identify_text_tool', 'description': 'Identify_text_tool(image: str) -> int - This tool should not be used on human, animals or anything else except texts. It is used to identify the text content in the image', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'Identify_object_tool', 'description': 'Identify_object_tool(image: str) -> str - This tool should not be used on human. It is used to identify a object in the image, such as a pencil, a window and so on.', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'route', 'description': 'Select the next role.', 'parameters': {'title': 'routeSchema', 'type': 'object', 'properties': {'next': {'title': 'Next', 'anyOf': [{'enum': ['FINISH', 'Face_recognition_tool', 'KB_tool', 'Count_text_len_tool', 'Identify_text_tool', 'Identify_object_tool']}]}}, 'required': ['next']}}], 'function_call': {'name': 'route'}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Pregel.stream() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 193\u001b[0m\n\u001b[1;32m    189\u001b[0m graph \u001b[38;5;241m=\u001b[39m workflow\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# 1. Stream\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# {\u001b[39;49;00m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     \"messages\": [\u001b[39;49;00m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#         HumanMessage(\u001b[39;49;00m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#             content=\"\"\"Write me a report on spaceX. After the research on spaceX,\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#                           pass the findings to the news editor to generate the final publication.\u001b[39;49;00m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#                           Once done, pass it to the ads writter to write the ads on the subject.\"\"\"\u001b[39;49;00m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#         )\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     ],\u001b[39;49;00m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# },\u001b[39;49;00m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# # Maximum number of steps to take in the graph\u001b[39;49;00m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# {\"recursion_limit\": 150}\u001b[39;49;00m\n\u001b[1;32m    205\u001b[0m \u001b[43m)\u001b[49m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__end__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m s:\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28mprint\u001b[39m((llm))\n",
      "\u001b[0;31mTypeError\u001b[0m: Pregel.stream() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import operator\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "\n",
    "# Set environment variables\n",
    "\n",
    "# Initialize model\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "# define custom tools to use\n",
    "\n",
    "\n",
    "@tool(\"process_search_tool\", return_direct=False)\n",
    "def process_search_tool(url: str) -> str:\n",
    "    \"\"\"Used to process content found on the internet.\"\"\"\n",
    "    response = requests.get(url=url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "\n",
    "@tool(\"internet_search_tool\", return_direct=False)\n",
    "def internet_search_tool(query: str) -> str:\n",
    "    \"\"\"Search provided query on the internet using DuckDuckGo\"\"\"\n",
    "\n",
    "    return \"No results found\"\n",
    "\n",
    "\n",
    "tools = [process_search_tool]\n",
    "\n",
    "\n",
    "def create_agents(llm: ChatOpenAI, #create an agent executor\n",
    "                  tools: list,\n",
    "                  system_prompt: str) -> AgentExecutor:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "    ])\n",
    "\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "\n",
    "# List of agents\n",
    "members = [\"news_correspondent\", \"news_editor\", \"ads_writter\"]\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee the insight between these\"\n",
    "    \" workers: {members}. Based on the user's request,\"\n",
    "    \" determine which worker should take the next action. Each worker is responsible for\"\n",
    "    \" executing a specific task and reporting back thier findings and progress.\"\n",
    "    \" Once all tasks are completed, indicate 'FINISH'.\"\n",
    ")\n",
    "\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"next\": {\"title\": \"Next\", \"anyOf\": [{\"enum\": options}]}},\n",
    "        \"required\": [\"next\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"system\",\n",
    "     \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "]).partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "supervisor_chain = (prompt | llm.bind_functions(\n",
    "    functions=[function_def], function_call=\"route\") | JsonOutputFunctionsParser())\n",
    "\n",
    "\n",
    "news_correspondent_agent = create_agents(\n",
    "    llm,\n",
    "    tools,\n",
    "    \"\"\"Your primary role is to function as an intelligent news research assistant, adept at scouring \n",
    "    the internet for the latest and most relevant trending stories across various sectors like politics, technology, \n",
    "    health, culture, and global events. You possess the capability to access a wide range of online news sources, \n",
    "    blogs, and social media platforms to gather real-time information.\"\"\"\n",
    ")\n",
    "\n",
    "news_correspondent_node = functools.partial(\n",
    "    agent_node, agent=news_correspondent_agent, name=\"news_correspondent\"\n",
    ")\n",
    "\n",
    "\n",
    "news_editor_agent = create_agents(\n",
    "    llm, tools,\n",
    "    \"\"\"You are a news editor. Do step by step approach. \n",
    "        Based on the provided content first identify the list of topics,\n",
    "        then search internet for each topic one by one\n",
    "        and finally find insights for each topic one by one that can aid you \n",
    "        in writting a useful news edition for AI-nes corp.\n",
    "        Include the insights and sources in the final response\n",
    "        \"\"\")\n",
    "# changed from news_editor_node => news_editor\n",
    "news_editor_node = functools.partial(\n",
    "    agent_node, agent=news_editor_agent, name=\"news_editor\")\n",
    "\n",
    "\n",
    "ads_writter_agent = create_agents(\n",
    "    llm, tools,\n",
    "    \"\"\"You are an ads writter for AI-news corp. Given the publication generated by the\n",
    "    news editor, your work if to write ads that relate to that content. Use the internet \n",
    "    to search for content to write ads based off on. Here is a description of your task:\n",
    "    \n",
    "    To craft compelling and relevant advertisements for 'AI News' publication, complementing the content written by the news editor.\n",
    "    Contextual Ad Placement: Analyze the final report content from the news editor in-depth to identify key themes, topics, \n",
    "    and reader interests. Place ads that are contextually relevant to these findings, thereby increasing potential customer engagement.\n",
    "    Advanced Image Sourcing and Curation: Employ sophisticated web search algorithms to source high-quality, relevant images for each ad. \n",
    "    Ensure these images complement the ad content and are aligned with the publication's aesthetic standards.\n",
    "    Ad-Content Synchronization: Seamlessly integrate advertisements with the report, ensuring they enhance rather than disrupt the reader's \n",
    "    experience. Ads should feel like a natural extension of the report, offering value to the reader.\n",
    "    Reference and Attribution Management: For each image sourced, automatically generate and include appropriate references and attributions, \n",
    "    ensuring compliance with copyright laws and ethical standards.\n",
    "    \"\"\")\n",
    "ads_writter_node = functools.partial(\n",
    "    agent_node, agent=ads_writter_agent, name=\"ads_writter\")\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "\n",
    "# Create workflow or graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# adding nodes\n",
    "workflow.add_node(key=\"supervisor\", action=supervisor_chain)\n",
    "workflow.add_node(key=\"news_correspondent\", action=news_correspondent_node)\n",
    "workflow.add_node(key=\"news_editor\", action=news_editor_node)\n",
    "workflow.add_node(key=\"ads_writter\", action=ads_writter_node)\n",
    "\n",
    "\n",
    "# define edgs\n",
    "for member in members:\n",
    "    workflow.add_edge(start_key=member, end_key=\"supervisor\")\n",
    "\n",
    "\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map['FINISH'] = END\n",
    "\n",
    "# if task is FINISHED, supervisor won't send task to agent, else,\n",
    "# the supervisor will keep on sending task to agent untill done, this is\n",
    "# what the conditional edge does.\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "\n",
    "# print(workflow.branches)\n",
    "# print(workflow.edges)\n",
    "# print(workflow.nodes)\n",
    "# print(workflow.channels)\n",
    "\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "\n",
    "# 1. Stream\n",
    "for s in graph.stream(\n",
    "    # {\n",
    "    #     \"messages\": [\n",
    "    #         HumanMessage(\n",
    "    #             content=\"\"\"Write me a report on spaceX. After the research on spaceX,\n",
    "    #                           pass the findings to the news editor to generate the final publication.\n",
    "    #                           Once done, pass it to the ads writter to write the ads on the subject.\"\"\"\n",
    "    #         )\n",
    "    #     ],\n",
    "    # },\n",
    "    # # Maximum number of steps to take in the graph\n",
    "    # {\"recursion_limit\": 150}\n",
    "):\n",
    "    if not \"__end__\" in s:\n",
    "        print((llm))\n",
    "        print(s, end=\"\\n\\n-----------------\\n\\n\")\n",
    "\n",
    "\n",
    "# 2. No Streaming\n",
    "# final_respone = graph.invoke({\n",
    "#     \"messages\": [HumanMessage(content=\"\"\"Write me a report on spaceX. After the research on spaceX,\n",
    "#                               pass the findings to the news editor to generate the final publication.\n",
    "#                               Once done, pass it to the ads writter to write the ads on the subject.\"\"\")]\n",
    "# }, {\"recursion_limit\": 150})\n",
    "\n",
    "# print(final_respone[\"messages\"][1].content)\n",
    "\n",
    "\n",
    "# def run_graph(input_message):\n",
    "#     response = graph.invoke({\n",
    "#         \"messages\": [HumanMessage(content=input_message)]\n",
    "#     }, {\"recursion_limit\": 150})\n",
    "#     return response['messages'][1].content\n",
    "\n",
    "\n",
    "# inputs = gr.components.Textbox(lines=2, placeholder=\"Enter your query here...\")\n",
    "# outputs = gr.components.Markdown()\n",
    "\n",
    "# demo = gr.Interface(\n",
    "#     fn=run_graph,\n",
    "#     inputs=inputs,\n",
    "#     outputs=outputs\n",
    "# )\n",
    "\n",
    "# demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['a', 'b']\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The tools that can be used on the target \"person\" (Einstein) are:\\n\\n1. Face_recognition_tool: This tool can be used to recognize and identify the face of the person in the image.\\n2. Identify_text_tool: This tool can be used to identify any text content associated with the person, such as captions, quotes, or descriptions.\\n3. Identify_object_tool: This tool can be used to identify other objects or items that may be present in the image along with the person.\\n\\nThese tools can help gather insights and information specifically related to the person (Einstein) in the image.')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbol\", temperature=0)#gpt-3.5-turbol\n",
    "\n",
    "system_prompt = (\n",
    "        \"As an AI, you are equipped with several tools to gather insights. Read the following words carefully before making a decision.\"\n",
    "        # \"You should help me VQA problem, but notice that I will use you for several times, and each time you only need to solve a small problem. \"\n",
    "        # \"Determine what tool you want to use next. \"\n",
    "        # \"I analyze the image by divding a image into a few parts by myself. For example, a image can be divided into cars, traffic light, pedestrian and so on. \"\n",
    "        # \"Then, I will analyze each part seperately by using tools that are suitable for some specific part. \"\n",
    "        \n",
    "        # \"currently, this image is about a person. \"\n",
    "        # \"Firstly, know about your binded tools by reading the prompt of information of the tools.\"\n",
    "        # \"Secondly, consider if you want to use the tools on the person.\"\n",
    "        # # \"The tools should be used to know more information only about the person in the image. \"\n",
    "        # # # \"Don't use 'Face_recognition_tool', which have been used.\"\n",
    "        # # \"'Face_recognition_tool'  and 'KB_tool' have been used. And don't use them again.\"\n",
    "\n",
    "        # # \"Before selecting tools, you should read the information about the binded tools by langchain carefully, because currently the tools should only be used on the person.\" \n",
    "        # # \"Select it carefully and thoughtfully. After selecting the appropriate tools, briefly explain the rationale behind your choice. Check if you can use the tool by reading the tool's information. \"\n",
    "        # \"Thirdly, 1.If you think you think you should use some tools, choose the best tool. \"\n",
    "        # \"After selecting the appropriate tools, briefly explain the rationale behind your choice. \"\n",
    "        # \"2. If you think the tools are meaningless to use or have limited benefit, then choose finish this task. \"\n",
    "        \"I want you to help me deal with the object in the image. \"\n",
    "        \"The image only has one \"\n",
    "        \"This person is Einstein.\"\n",
    "        \"He was an expert in physics.\"\n",
    "        \"Read descriptions of all the tools that you binded with. \"\n",
    "        \"The current target is : person\"\n",
    "        \"You don't have to care other object or people around the target currently.\"\n",
    "\n",
    "        \"For example, you don't have to care the \"\n",
    "        \"Which tools do you think you can use on the target? List them.\"\n",
    "        # \"Remind your current result and thought.\"\n",
    "        # \"You have two choices:\"\n",
    "        # \"1.If you are sure that a tool that is binded is useful by description, output its name. \"\n",
    "        # # \"After selecting the appropriate tools, briefly explain the rationale behind your choice. \"\n",
    "        # \"2. If you think the tools are meaningless to use or have limited benefit, then choose finish this task. \"\n",
    "       \n",
    "        \n",
    "\n",
    ")\n",
    "\n",
    "a=llm.invoke(system_prompt)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "chatgpt2 = OpenAI(model_name=\"gpt-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'function_call': {'arguments': '{\"tools\":\"Identify_object_tool\"}', 'name': 'route'}}\n",
      "content='' additional_kwargs={'function_call': {'arguments': '{\"tools\":\"KB_tool\"}', 'name': 'route'}}\n",
      "content='' additional_kwargs={'function_call': {'arguments': '{\"tools\":\"KB_tool\"}', 'name': 'route'}}\n",
      "content='' additional_kwargs={'function_call': {'arguments': '{\"tools\":\"Identify_object_tool\"}', 'name': 'route'}}\n",
      "content='' additional_kwargs={'function_call': {'arguments': '{\"tools\":\"KB_tool\"}', 'name': 'route'}}\n",
      "content='' additional_kwargs={'function_call': {'arguments': '{\"tools\":\"KB_tool\"}', 'name': 'route'}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 97\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# llm.kwargs['functions'].append({'name': 'route', 'description': 'Make a good format ', 'parameters': {'title': 'selected tools', 'type': 'object', 'properties': {'tools': {'title': 'Tools', 'type': 'string'}}, 'required': ['tools']}})\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# llm.kwargs['function_call']= {'name': 'route'}\u001b[39;00m\n\u001b[1;32m     83\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAs an AI, you are equipped with several tools to gather insights. Question: Does the person in the image do research about the cat? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# \"Determine what tool you want to use next. \"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m )\n\u001b[0;32m---> 97\u001b[0m a\u001b[38;5;241m=\u001b[39m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m llm\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroute\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMake a good format \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselected tools\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTools\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m}}, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequired\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m'\u001b[39m]}})\n\u001b[1;32m    100\u001b[0m llm\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroute\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py:4060\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4054\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   4055\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4056\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   4057\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4058\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4059\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 4060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4061\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4062\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4063\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4064\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:166\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    162\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    163\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    165\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 166\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    175\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:544\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    538\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    542\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    543\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:408\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    407\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 408\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    409\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    410\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    412\u001b[0m ]\n\u001b[1;32m    413\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:398\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 398\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m         )\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:577\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m     )\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:462\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    457\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    461\u001b[0m }\n\u001b[0;32m--> 462\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/openai/resources/chat/completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    662\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/openai/_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1199\u001b[0m     )\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/openai/_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/openai/_base_client.py:918\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    915\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 918\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    924\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1257\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1258\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    from langchain.tools import tool\n",
    "    import requests\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol\n",
    "\n",
    "    def search_wikipedia(query):\n",
    "        URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "        \n",
    "        PARAMS = {\n",
    "            \"action\": \"opensearch\",\n",
    "            \"search\": query,\n",
    "            \"limit\": 5,\n",
    "            \"namespace\": 0,\n",
    "            \"format\": \"json\"\n",
    "        }\n",
    "        \n",
    "        response = requests.get(URL, params=PARAMS)\n",
    "        data = response.json()\n",
    "        \n",
    "        print(data)\n",
    "        if len(data) > 1 and isinstance(data[1], list):\n",
    "\n",
    "            for title in data[1]:\n",
    "                print(title)\n",
    "        return data\n",
    "    @tool(\"Face_recognition_tool\", return_direct=False)\n",
    "    def Face_recognition_tool(image_input: str) -> str:#imag 类别修改\n",
    "        \"\"\"This tool is only used for human. It return the name of a person by face recognition.\"\"\"\n",
    "        # image = Image.open(image_input).convert('RGB')   \n",
    "        # prompt = \"Question: who is the person? Answer:\" # Person 这个信息是从entity tool来的。\n",
    "\n",
    "        # inputs = processor(image, text=prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "\n",
    "        # generated_ids = model.generate(**inputs, max_new_tokens=10)\n",
    "        # generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "        # print(generated_text)\n",
    "\n",
    "        return 'Bruce Lee'\n",
    "    # @tool(\"route\",return_direct=True)\n",
    "    # def route(next):\n",
    "    #     \"Select the next role.\"\n",
    "\n",
    "\n",
    "    @tool(\"KB_tool\", return_direct=True)\n",
    "    def KB_tool(obj:str) -> str:#imag 类别修改\n",
    "        \"\"\"This tool is only used after knowing the name of a person or a object, and this tool is used to search more information in wikipedia\"\"\"\n",
    "        # query = obj\n",
    "        \n",
    "        # a=search_wikipedia(query)\n",
    "        # rag_chain=search_in_rag(a)\n",
    "        # ans=rag_chain.invoke(\"Does Einstein do research about cat\")\n",
    "        return 'No, he did not do research about the cat'\n",
    "        # return ans\n",
    "    @tool(\"Count_text_len_tool\", return_direct=True)\n",
    "    def Count_text_len_tool(text:str) -> int:#imag 类别修改\n",
    "        \"\"\"This tool should only be used for text information, and it is used to count the text length of the text\"\"\"\n",
    "        return 5\n",
    "    @tool(\"Identify_text_tool\", return_direct=True)\n",
    "    def Identify_text_tool(image:str) -> int:#imag 类别修改\n",
    "        \"\"\"This tool should only be used for text information, and it is used to identify the text content in the image\"\"\"\n",
    "        return 5\n",
    "    @tool(\"Identify_object_tool\", return_direct=True)\n",
    "    def Identify_object_tool(image:str) -> str:#imag 类别修改\n",
    "        \"\"\"This tool is used to identify other objects except human\"\"\"\n",
    "        return 'cat'\n",
    "\n",
    "\n",
    "    tools=[Face_recognition_tool,KB_tool,Count_text_len_tool,Identify_text_tool,Identify_object_tool]\n",
    "    from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "    functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "    llm = llm.bind_functions(functions)\n",
    "\n",
    "    from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "    tool_executor = ToolExecutor(tools)\n",
    "    # llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)#gpt-3.5-turbol\n",
    "    # llm.kwargs['functions'].append({'name': 'route', 'description': 'Make a good format ', 'parameters': {'title': 'selected tools', 'type': 'object', 'properties': {'tools': {'title': 'Tools', 'type': 'string'}}, 'required': ['tools']}})\n",
    "\n",
    "    # llm.kwargs['function_call']= {'name': 'route'}\n",
    "\n",
    "    system_prompt = (\n",
    "        \"As an AI, you are equipped with several tools to gather insights. Question: Does the person in the image do research about the cat? \"\n",
    "        # \"Determine what tool you want to use next. \"\n",
    "        \"The tools should be used to know more information about the person in the image. \"\n",
    "        # # \"Don't use 'Face_recognition_tool', which have been used.\"\n",
    "        # \"'Face_recognition_tool'  and 'KB_tool' have been used. And don't use them again.\"\n",
    "\n",
    "        \"If you think  tools are not really useful: choose 'FINISH'. \"\n",
    "        \"Else:  select other tools. After selecting the appropriate tools, briefly explain the rationale behind your choice. \"\n",
    "        # \"Given the conversation above, which tools do you want to use?\"\n",
    "\n",
    "\n",
    "    )\n",
    "\n",
    "    a=llm.invoke(system_prompt)\n",
    "    llm.kwargs['functions'].append({'name': 'route', 'description': 'Make a good format ', 'parameters': {'title': 'selected tools', 'type': 'object', 'properties': {'tools': {'title': 'Tools', 'type': 'string'}}, 'required': ['tools']}})\n",
    "\n",
    "    llm.kwargs['function_call']= {'name': 'route'}\n",
    "    a=llm.invoke(a.content)\n",
    "    print(a)\n",
    "    # supervisor_chain = (prompt|llm|JsonOutputFunctionsParser)\n",
    "\n",
    "# supervisor_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f28e04eb820>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f28e0f768c0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'functions': [{'name': 'Face_recognition_tool', 'description': 'Face_recognition_tool(image_input: str) -> str - This tool is only used for human. It return the name of a person by face recognition.', 'parameters': {'type': 'object', 'properties': {'image_input': {'type': 'string'}}, 'required': ['image_input']}}, {'name': 'KB_tool', 'description': 'KB_tool(obj: str) -> str - This tool is only used after knowing the name of a person or a object after using \"Obj_recognition_tool\", and this tool is used to search more information in wikipedia', 'parameters': {'type': 'object', 'properties': {'obj': {'type': 'string'}}, 'required': ['obj']}}, {'name': 'Count_text_len_tool', 'description': 'Count_text_len_tool(text: str) -> int - This tool should only be used for text information, and it is used to count the text length of the text', 'parameters': {'type': 'object', 'properties': {'text': {'type': 'string'}}, 'required': ['text']}}, {'name': 'Identify_text_tool', 'description': 'Identify_text_tool(image: str) -> int - This tool should only be used for text information, and it is used to identify the text content in the image', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'Identify_object_tool', 'description': 'Identify_object_tool(image: str) -> str - This tool is used to identify other objects except human', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'route', 'description': 'Select the next role.', 'parameters': {'title': 'routeSchema', 'type': 'object', 'properties': {'next': {'title': 'Next', 'anyOf': [{'enum': ['FINISH', 'Face_recognition_tool', 'KB_tool', 'Count_text_len_tool', 'Identify_text_tool', 'Identify_object_tool']}]}}, 'required': ['next']}}], 'function_call': {'name': 'route'}})"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Face_recognition_tool', ' KB_tool']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "tool=json.loads(a.additional_kwargs['function_call']['arguments'])['tools']\n",
    "tool=tool.split(\",\")\n",
    "type(tool)\n",
    "tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools=[\"Face_recognition_tool\",\"KB_tool\",\"Count_text_len_tool\",\"Identify_text_tool\",\"Identify_object_tool\"]\n",
    "\n",
    "\n",
    "# openAIFunction = {\n",
    "#   \"name\": \"route\",\n",
    "#   \"description\": \"Select useful tools from a list of tools\",\n",
    "#   \"parameters\": {\n",
    "#     \"title\": \"selected tools\",\n",
    "#     \"type\": \"object\",\n",
    "#     \"properties\": {\n",
    "      \n",
    "#       \"tools\": { \"title\": \"Tools\",  \"type\": \"string\" },\n",
    "      \n",
    "#     },\n",
    "#     \"required\": [\"tools\"],\n",
    "#   },\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f28e1134160>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f28e12af2e0>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'functions': [{'name': 'Face_recognition_tool', 'description': 'Face_recognition_tool(image_input: str) -> str - This tool is only used for human. It return the name of a person by face recognition.', 'parameters': {'type': 'object', 'properties': {'image_input': {'type': 'string'}}, 'required': ['image_input']}}, {'name': 'KB_tool', 'description': 'KB_tool(obj: str) -> str - This tool is only used after knowing the name of a person or a object after using \"Obj_recognition_tool\", and this tool is used to search more information in wikipedia', 'parameters': {'type': 'object', 'properties': {'obj': {'type': 'string'}}, 'required': ['obj']}}, {'name': 'Count_text_len_tool', 'description': 'Count_text_len_tool(text: str) -> int - This tool should only be used for text information, and it is used to count the text length of the text', 'parameters': {'type': 'object', 'properties': {'text': {'type': 'string'}}, 'required': ['text']}}, {'name': 'Identify_text_tool', 'description': 'Identify_text_tool(image: str) -> int - This tool should only be used for text information, and it is used to identify the text content in the image', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'Identify_object_tool', 'description': 'Identify_object_tool(image: str) -> str - This tool is used to identify other objects except human', 'parameters': {'type': 'object', 'properties': {'image': {'type': 'string'}}, 'required': ['image']}}, {'name': 'route', 'description': 'Select the next role.', 'parameters': {'title': 'routeSchema', 'type': 'object', 'properties': {'next': {'title': 'Next', 'anyOf': [{'enum': ['FINISH', 'Face_recognition_tool', 'KB_tool', 'Count_text_len_tool', 'Identify_text_tool', 'Identify_object_tool']}]}}, 'required': ['next']}}]})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=llm.bind_functions(\n",
    "    functions=[openAIFunction], function_call=\"route\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"next\":\"Face_recognition_tool\"}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(a.additional_kwargs['function_call']['arguments'])\n",
    "import json\n",
    "print(type(ast.literal_eval(a.additional_kwargs['function_call']['arguments'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f27e1ee3b50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f27e1f19000>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'functions': [{'name': 'route', 'type': 'object', 'properties': {'selectedTools': {'type': 'array', 'title': 'Selected Tools', 'description': 'List of tools to be selected', 'items': {'type': 'string', 'enum': ['Face_recognition_tool', 'KB_tool', 'Count_text_len_tool', 'Identify_text_tool', 'Identify_object_tool']}}}, 'required': ['selectedTools']}], 'function_call': {'name': 'route'}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools=[\"Face_recognition_tool\",\"KB_tool\",\"Count_text_len_tool\",\"Identify_text_tool\",\"Identify_object_tool\"]\n",
    "# messages = state['messages'][-1]\n",
    "# print(messages.content)\n",
    "# name=ast.literal_eval(messages.content)\n",
    "\n",
    "system_prompt = (\n",
    "    \"As an AI, you are equipped with several tools to gather insights. \"\n",
    "    \n",
    "    # \"Each tool just use once. Remember each tool you have used, these tools can't be used again. \"\n",
    "    # \"If object is human. Use Face_recognition_tool and KB_tool\"\n",
    "    \"Select tools to yield information related to the person in the image. \"\n",
    "    \"After selecting the appropriate tools, briefly explain the rationale behind your choice. \"\n",
    "    # \"Once you you think all useful tools for the person in the image have been used, indicate 'FINISH'.\"\n",
    "    # \"Do you think KB_tool useful?\"\n",
    "    # \"Do you think Text_Len_tool useful?\"\n",
    "    # \"Do you think Identify_text_tool useful?\"\n",
    "    # \"Do you think Identify_object_tool useful?\"\n",
    "    \"Finally, output the tools' name you want to use.\"\n",
    "\n",
    ")\n",
    "options=[\"FINISH\"]+tools\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"As an AI, you are equipped with several tools to gather insights. \"),\n",
    "    (\"system\",\"Don't select tools in the value of the next dictionary, because they have been used.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"system\",\n",
    "    \"Select tools to yield information related to the person in the image. \"\n",
    "    \"After selecting the appropriate tools, briefly explain the rationale behind your choice. \"\n",
    "    \"Given the conversation above, which tool should be used next? Or should we FINISH? Select one of: {options}\"\n",
    "    ),\n",
    "]).partial(options=str(options))\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# def call_model(state):\n",
    "#     ans=llm.invoke(system_prompt) \n",
    "#     tools=json.loads(a.additional_kwargs['function_call']['arguments'])['tools']\n",
    "#     options=tools.split(\",\")\n",
    "\n",
    "#     options=['FINISH']+tools\n",
    "#     prompt = ChatPromptTemplate.from_messages([\n",
    "#     MessagesPlaceholder(variable_name=\"messages\"),\n",
    "#     (\"system\",\n",
    "#     \"Remember the too's name in the message, and don't use it again. Select tools one by one: {options},and finally choose 'FINISH'\"\n",
    "#     ),\n",
    "# ]).partial(options=str(options))\n",
    "    \n",
    "#     return {\"next\": [ans]}\n",
    "supervisor_chain = (prompt|llm|JsonOutputFunctionsParser())\n",
    "    # print(supervisor_chain)\n",
    "    # return ast.literal_eval(supervisor_chain.additional_kwargs['function_call']['arguments'])\n",
    "# supervisor_chain = (prompt | llm.bind_functions(\n",
    "#     functions=[function_def], function_call=\"route\") | JsonOutputFunctionsParser())\n",
    "# supervisor_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "prompt = \"May the {subject} be with you\"\n",
    "\n",
    "chat_message_prompt = ChatMessagePromptTemplate.from_template(\n",
    "    role=\"Jedi\", template=prompt\n",
    ")\n",
    "chat_message_prompt.format(subject=\"force\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'delete'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m([\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'delete'"
     ]
    }
   ],
   "source": [
    "a=['a','b','c']\n",
    "a.delete([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n"
     ]
    }
   ],
   "source": [
    "def call_Agent():\n",
    "    ['a','b','c']\n",
    "    global loader\n",
    "    loader=memory_loader(['f','b','c'])\n",
    "    Call_arranger('from agent')\n",
    "def memory_loader(l):\n",
    "\n",
    "    memory=l\n",
    "    i=0\n",
    "    def load_memory():\n",
    "        \n",
    "        nonlocal i\n",
    "        if i==len(l): return 'nothing left'\n",
    "        res=memory[i]\n",
    "        i+=1\n",
    "        return res\n",
    "    return load_memory\n",
    "\n",
    "def Call_arranger(input):\n",
    "    \n",
    "\n",
    "        \n",
    "    a=loader()\n",
    "    print(a)\n",
    "call_Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing left\n"
     ]
    }
   ],
   "source": [
    "Call_arranger('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import FunctionMessage\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "import ast\n",
    "import json\n",
    "def call_Face_recognition_tool(state):\n",
    "    action = ToolInvocation(\n",
    "        tool='Face_recognition_tool',\n",
    "        # tool_input=json.loads('{\"image_input\":\"/root/projects/Einstein2.png\"}'),\n",
    "        tool_input=json.loads('{\"image_input\":\"a.png\"}'),\n",
    "    )\n",
    "    response = tool_executor.invoke(action)#函数返回值\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"messages\": [function_message]}\n",
    "def call_KB_tool(state):\n",
    "    action = ToolInvocation(\n",
    "        tool='KB_tool',\n",
    "        # tool_input=json.loads('{\"obj\":\"Einstein\"}'),\n",
    "        tool_input=json.loads('{\"obj\":\"bilibili\"}'),\n",
    "    )\n",
    "    response = tool_executor.invoke(action)#函数返回值\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"messages\": [function_message]}\n",
    "def call_Count_text_len_tool(state):\n",
    "    action = ToolInvocation(\n",
    "        tool='Text_Len_tool',\n",
    "        tool_input=json.loads('{\"text\":\"balala\"}'),\n",
    "    )\n",
    "    response = tool_executor.invoke(action)#函数返回值\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"messages\": [function_message]}\n",
    "def call_Identify_text_tool(state):\n",
    "    action = ToolInvocation(\n",
    "        tool='Identify_text_tool',\n",
    "        tool_input=json.loads('{\"image\":\"adfs.png\"}'),\n",
    "    )\n",
    "    response = tool_executor.invoke(action)#函数返回值\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"messages\": [function_message]}\n",
    "def call_Identify_object_tool(state):\n",
    "    action = ToolInvocation(\n",
    "        tool='Identify_object_tool',\n",
    "        tool_input=json.loads('{\"image\":\"ok.png\"}'),\n",
    "    )\n",
    "    response = tool_executor.invoke(action)#函数返回值\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    return {\"messages\": [function_message]}\n",
    "# def call_Agent(state):\n",
    "#     system_prompt = (\n",
    "#         \"As an AI, you are equipped with several tools to gather insights. Question: Does the person in the image do research about the cat? \"\n",
    "#         # \"Determine what tool you want to use next. \"\n",
    "#         \"The tools should be used to know more information about the person in the image. \"\n",
    "#         # # \"Don't use 'Face_recognition_tool', which have been used.\"\n",
    "#         # \"'Face_recognition_tool'  and 'KB_tool' have been used. And don't use them again.\"\n",
    "\n",
    "#         \"If you think  tools are not really useful: choose 'FINISH'. \"\n",
    "#         \"Else:  select other tools. After selecting the appropriate tools, briefly explain the rationale behind your choice. \"\n",
    "#         # \"Given the conversation above, which tools do you want to use?\"\n",
    "\n",
    "\n",
    "#     )\n",
    "def call_Agent(input):\n",
    "    system_prompt = (\n",
    "        \"As an AI, you are equipped with several tools to gather insights. Question: Does the person in the image do research about the cat? \"\n",
    "        # \"Determine what tool you want to use next. \"\n",
    "        \"The tools should be used to know more information about the cat in the image. \"\n",
    "        # # \"Don't use 'Face_recognition_tool', which have been used.\"\n",
    "        # \"'Face_recognition_tool'  and 'KB_tool' have been used. And don't use them again.\"\n",
    "\n",
    "        \"If you think  tools are not really useful: choose 'FINISH'. \"\n",
    "        \"Else:  select other tools. After selecting the appropriate tools, briefly explain the rationale behind your choice. \"\n",
    "        # \"Given the conversation above, which tools do you want to use?\"\n",
    "\n",
    "\n",
    "    )\n",
    "\n",
    "    a=llm.invoke(system_prompt)\n",
    "    import json\n",
    "    tool=json.loads(a.additional_kwargs['function_call']['arguments'])['tools']\n",
    "    tool=tool.split(\",\")\n",
    "    # type(tool)\n",
    "\n",
    "    global loader\n",
    "    loader=memory_loader(tool)\n",
    "    return {\"messages\":tool}\n",
    "\n",
    "def memory_loader(l):\n",
    "\n",
    "    memory=l\n",
    "    i=0\n",
    "    def load_memory():\n",
    "        \n",
    "        nonlocal i\n",
    "        if i==len(l): return 'FINISH'\n",
    "        res=memory[i]\n",
    "        i+=1\n",
    "        return res\n",
    "    return load_memory\n",
    "\n",
    "def Call_Arranger(input):\n",
    "    \n",
    "\n",
    "        \n",
    "    option=loader()\n",
    "    return {\"next\": option}\n",
    "# def memory_loader():\n",
    "\n",
    "#     memory=[]\n",
    "#     def load_memory(new_msg):\n",
    "        \n",
    "        \n",
    "#         memory.append(new_msg)\n",
    "#         return memory\n",
    "#     return load_memory\n",
    "# loader = memory_loader()\n",
    "# def Call_Data_collecter(state):\n",
    "#     print(MessagesPlaceholder(variable_name=\"messages\"))\n",
    "#     curtool=state['next']\n",
    "#     tool_used=loader(curtool)\n",
    "#     return {\"messages\": tool_used}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': {'messages': 1}}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def memory_loader():\n",
    "#     memory = []\n",
    "\n",
    "#     def load_memory(new_msg):\n",
    "#         # 假设 new_msg.content 是可迭代的\n",
    "#         memory.append(list(new_msg.content))\n",
    "#         return memory  # 返回更新后的内存\n",
    "\n",
    "#     return load_memory  # 返回内部函数\n",
    "\n",
    "# loader = memory_loader()\n",
    "\n",
    "# def call_data_collector(state):\n",
    "#     messages = state['messages']\n",
    "#     last_message = messages[-1]\n",
    "#     memory = loader(last_message)  # 更新内存\n",
    "#     print(memory)\n",
    "#     return {\"messages\": memory}\n",
    "\n",
    "# Call_Data_collecter({'messages':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\n",
      "[10, 20]\n",
      "[30]\n"
     ]
    }
   ],
   "source": [
    "# def memory_loader():\n",
    "#     # 这里的 memory 变量会被内嵌的函数 load_memory 访问\n",
    "#     memory = []\n",
    "\n",
    "#     def load_memory(new_data):\n",
    "#         # 这里我们可以访问外部函数的 memory 变量，并且修改它\n",
    "#         memory.append(new_data)\n",
    "#         return memory\n",
    "\n",
    "#     return load_memory\n",
    "\n",
    "# # 使用闭包\n",
    "# loader = memory_loader()\n",
    "\n",
    "# # 每次调用 loader 时，都会在 memory 中累加元素，而不会从头开始\n",
    "# print(loader(10))  # 输出: [10]\n",
    "# print(loader(20))  # 输出: [10, 20]\n",
    "# loader = memory_loader()\n",
    "# print(loader(30))  # 输出: [10, 20, 30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 20, 30, 'balaf']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def call_model(state):\n",
    "#     messages = state['messages']\n",
    "    \n",
    "#     print('messsage:',messages)\n",
    "#     response = model.invoke(messages)\n",
    "#     return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何让agent做判断：supervisor +prompt 根据内容 person cat book/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def should_continue(state):\n",
    "#     messages = state['messages']\n",
    "#     last_message = messages[-1]\n",
    "#     print(messages)\n",
    "#     # print(\"state'next:\"+state['next'])\n",
    "#     # If there is no function call, then we finish\n",
    "#     if \"function_call\" not in last_message.additional_kwargs:\n",
    "#         return \"end\"\n",
    "#     # Otherwise if there is, we continue\n",
    "#     else :\n",
    "#         print(last_message.additional_kwargs[\"function_call\"][\"arguments\"])\n",
    "#         return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Face_recognition_tool': 'Face_recognition_tool', 'KB_tool': 'KB_tool', 'Count_text_len_tool': 'Count_text_len_tool', 'Identify_text_tool': 'Identify_text_tool', 'Identify_object_tool': 'Identify_object_tool', 'FINISH': '__end__'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "# import ipydb\n",
    "# Define a new graph\n",
    "tools=[\"Face_recognition_tool\",\"KB_tool\",\"Count_text_len_tool\",\"Identify_text_tool\",\"Identify_object_tool\"]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_Agent)#不确定应该call_model还是用chain，这里先尝试chain\n",
    "# workflow.add_node(\"data_collecter\", Call_Data_collecter)#不确定应该call_model还是用chain，这里先尝试chain\n",
    "workflow.add_node(\"arranger\", Call_Arranger)#不确定应该call_model还是用chain，这里先尝试chain\n",
    "workflow.add_node(\"Face_recognition_tool\", call_Face_recognition_tool)\n",
    "workflow.add_node(\"KB_tool\", call_KB_tool)\n",
    "workflow.add_node(\"Count_text_len_tool\", call_Count_text_len_tool)\n",
    "workflow.add_node(\"Identify_text_tool\", call_Identify_text_tool)\n",
    "workflow.add_node(\"Identify_object_tool\", call_Identify_object_tool)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "conditional_map = {k: k for k in tools}\n",
    "conditional_map['FINISH'] = END\n",
    "print(conditional_map)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"arranger\", lambda x: x[\"next\"], conditional_map)\n",
    "\n",
    "for tool in tools:\n",
    "    workflow.add_edge(start_key=tool, end_key=\"arranger\")\n",
    "workflow.add_edge(start_key=\"agent\", end_key=\"arranger\")\n",
    "\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "# workflow.add_edge('action', 'agent')\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "('agent', {'messages': ['Face_recognition_tool', 'KB_tool', 'Identify_object_tool']})\n",
      "\n",
      "---\n",
      "\n",
      "---\n",
      "('arranger', {'next': 'Face_recognition_tool'})\n",
      "\n",
      "---\n",
      "\n",
      "---\n",
      "('Face_recognition_tool', {'messages': [FunctionMessage(content='Bruce Lee', name='Face_recognition_tool')]})\n",
      "\n",
      "---\n",
      "\n",
      "---\n",
      "('arranger', {'next': 'KB_tool'})\n",
      "\n",
      "---\n",
      "\n",
      "---\n",
      "('KB_tool', {'messages': [FunctionMessage(content='No, he did not do research about the cat', name='KB_tool')]})\n",
      "\n",
      "---\n",
      "\n",
      "---\n",
      "('arranger', {'next': 'Identify_object_tool'})\n",
      "\n",
      "---\n",
      "\n",
      "---\n",
      "('Identify_object_tool', {'messages': [FunctionMessage(content='cat', name='Identify_object_tool')]})\n",
      "\n",
      "---\n",
      "\n",
      "---\n",
      "('arranger', {'next': 'FINISH'})\n",
      "\n",
      "---\n",
      "\n",
      "---\n",
      "('__end__', {'messages': [HumanMessage(content=''), 'Face_recognition_tool', 'KB_tool', 'Identify_object_tool', FunctionMessage(content='Bruce Lee', name='Face_recognition_tool'), FunctionMessage(content='No, he did not do research about the cat', name='KB_tool'), FunctionMessage(content='cat', name='Identify_object_tool')], 'next': 'FINISH'})\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inputs = {\"messages\": [(HumanMessage(content=\"\"))]}\n",
    "inputs = {\"messages\": [(HumanMessage(content=\"\"))]}\n",
    "for output in app.stream(inputs):\n",
    "    # ipydb.settrace\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for a in output.items():\n",
    "        # print(f\"Output from node '{key}':\")\n",
    "        # print(a[0][\"next\"])\n",
    "        print(\"---\")\n",
    "        print(a)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Identify_object_tool'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a={'messages': [HumanMessage(content=''), FunctionMessage(content='Bruce Lee', name='Face_recognition_tool'), 'this is from collecter', FunctionMessage(content='No, he did not do research about the cat', name='KB_tool'), 'this is from collecter', FunctionMessage(content='Bruce Lee', name='Face_recognition_tool'), 'this is from collecter', FunctionMessage(content='cat', name='Identify_object_tool')], 'next': 'Identify_object_tool'}\n",
    "a['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news_correspondent': 'news_correspondent', 'news_editor': 'news_editor', 'ads_writter': 'ads_writter'}\n",
      "('supervisor', {'next': 'news_correspondent'})\n",
      "{'supervisor': {'next': 'news_correspondent'}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('news_correspondent', {'messages': [HumanMessage(content=\"### SpaceX Research Report\\n\\n**Introduction:**\\nSpaceX, formally known as Space Exploration Technologies Corp., is a pioneering force in the modern aerospace industry. Founded by Elon Musk in 2002, the company has made significant strides in reducing space transportation costs and enhancing the reliability of access to space. This report delves into SpaceX's history, achievements, future plans, and its overall impact on space exploration and satellite communication.\\n\\n**Historical Background:**\\nSpaceX was established with the ambitious goal of making space travel more affordable and ultimately enabling the colonization of Mars. The company's journey began with the Falcon 1 rocket, which became the first privately funded, liquid-fueled rocket to reach orbit in 2008. Since then, SpaceX has developed a series of advanced rockets and spacecraft, including the Falcon 9, Falcon Heavy, and the Dragon spacecraft.\\n\\n**Key Achievements:**\\n1. **Reusability:** SpaceX has revolutionized space travel with its reusable rocket technology, significantly reducing the cost of access to space. The Falcon 9 rocket's first stage has successfully landed over 200 times, enabling multiple reuses.\\n\\n2. **Commercial and Government Contracts:** SpaceX has secured numerous contracts for cargo and crew missions to the International Space Station (ISS), national defense, and satellite deployments, becoming a key player in both commercial and government sectors.\\n\\n3. **Starlink:** Through its subsidiary, SpaceX has deployed the Starlink satellite constellation, offering broadband internet service worldwide. With over 5,000 satellites in orbit as of November 2023, Starlink represents the largest satellite constellation in operation.\\n\\n4. **Crewed Space Missions:** In May 2020, SpaceX achieved a historic milestone by launching NASA astronauts to the ISS aboard the Crew Dragon spacecraft, marking the first crewed orbital launch from the United States in nearly a decade.\\n\\n5. **Starship Development:** SpaceX is developing the Starship spacecraft for missions to the Moon, Mars, and beyond. Despite some setbacks in early test flights, Starship represents SpaceX's commitment to interplanetary travel.\\n\\n**Future Endeavors:**\\nSpaceX continues to work on ambitious projects, including the further development of the Starship for crewed Mars missions, expansion of the Starlink network, and partnerships for lunar exploration under NASA's Artemis program. The company's valuation, as of December 2023, stands at around $180 billion, reflecting its significant impact on the aerospace industry.\\n\\n**Conclusion:**\\nSpaceX has established itself as a leader in space exploration and satellite communication, continuously pushing the boundaries of what is possible. With a focus on innovation, reusability, and affordability, SpaceX's contributions are paving the way for a new era of space travel and connectivity, making the vastness of space more accessible to humanity.\\n\\n### Next Steps:\\n\\n- **For the News Editor:** This report on SpaceX provides a comprehensive overview of the company's history, achievements, and future plans. It highlights SpaceX's role in reducing the cost of space access and its contributions to satellite communication and space exploration. The information should be valuable for generating a final publication that captures SpaceX's impact on the aerospace industry and its significance in advancing human spaceflight and global connectivity.\\n\\n- **For the Ads Writer:** Based on the findings of this report, there's a strong narrative around innovation, exploration, and connectivity that can be leveraged for creating compelling advertisements. Emphasizing SpaceX's achievements in reusable rocket technology, the expansion of the Starlink network, and the development of the Starship could appeal to a wide audience interested in technology, space exploration, and the future of internet connectivity. Highlighting the vision of making life multiplanetary could also resonate deeply with the audience's imagination and aspirations.\", name='news_correspondent')]})\n",
      "{'news_correspondent': {'messages': [HumanMessage(content=\"### SpaceX Research Report\\n\\n**Introduction:**\\nSpaceX, formally known as Space Exploration Technologies Corp., is a pioneering force in the modern aerospace industry. Founded by Elon Musk in 2002, the company has made significant strides in reducing space transportation costs and enhancing the reliability of access to space. This report delves into SpaceX's history, achievements, future plans, and its overall impact on space exploration and satellite communication.\\n\\n**Historical Background:**\\nSpaceX was established with the ambitious goal of making space travel more affordable and ultimately enabling the colonization of Mars. The company's journey began with the Falcon 1 rocket, which became the first privately funded, liquid-fueled rocket to reach orbit in 2008. Since then, SpaceX has developed a series of advanced rockets and spacecraft, including the Falcon 9, Falcon Heavy, and the Dragon spacecraft.\\n\\n**Key Achievements:**\\n1. **Reusability:** SpaceX has revolutionized space travel with its reusable rocket technology, significantly reducing the cost of access to space. The Falcon 9 rocket's first stage has successfully landed over 200 times, enabling multiple reuses.\\n\\n2. **Commercial and Government Contracts:** SpaceX has secured numerous contracts for cargo and crew missions to the International Space Station (ISS), national defense, and satellite deployments, becoming a key player in both commercial and government sectors.\\n\\n3. **Starlink:** Through its subsidiary, SpaceX has deployed the Starlink satellite constellation, offering broadband internet service worldwide. With over 5,000 satellites in orbit as of November 2023, Starlink represents the largest satellite constellation in operation.\\n\\n4. **Crewed Space Missions:** In May 2020, SpaceX achieved a historic milestone by launching NASA astronauts to the ISS aboard the Crew Dragon spacecraft, marking the first crewed orbital launch from the United States in nearly a decade.\\n\\n5. **Starship Development:** SpaceX is developing the Starship spacecraft for missions to the Moon, Mars, and beyond. Despite some setbacks in early test flights, Starship represents SpaceX's commitment to interplanetary travel.\\n\\n**Future Endeavors:**\\nSpaceX continues to work on ambitious projects, including the further development of the Starship for crewed Mars missions, expansion of the Starlink network, and partnerships for lunar exploration under NASA's Artemis program. The company's valuation, as of December 2023, stands at around $180 billion, reflecting its significant impact on the aerospace industry.\\n\\n**Conclusion:**\\nSpaceX has established itself as a leader in space exploration and satellite communication, continuously pushing the boundaries of what is possible. With a focus on innovation, reusability, and affordability, SpaceX's contributions are paving the way for a new era of space travel and connectivity, making the vastness of space more accessible to humanity.\\n\\n### Next Steps:\\n\\n- **For the News Editor:** This report on SpaceX provides a comprehensive overview of the company's history, achievements, and future plans. It highlights SpaceX's role in reducing the cost of space access and its contributions to satellite communication and space exploration. The information should be valuable for generating a final publication that captures SpaceX's impact on the aerospace industry and its significance in advancing human spaceflight and global connectivity.\\n\\n- **For the Ads Writer:** Based on the findings of this report, there's a strong narrative around innovation, exploration, and connectivity that can be leveraged for creating compelling advertisements. Emphasizing SpaceX's achievements in reusable rocket technology, the expansion of the Starlink network, and the development of the Starship could appeal to a wide audience interested in technology, space exploration, and the future of internet connectivity. Highlighting the vision of making life multiplanetary could also resonate deeply with the audience's imagination and aspirations.\", name='news_correspondent')]}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('supervisor', {'next': 'news_editor'})\n",
      "{'supervisor': {'next': 'news_editor'}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('news_editor', {'messages': [HumanMessage(content=\"### SpaceX Research Update for AI-nes Corp News Edition\\n\\n**Introduction:**\\n\\nIn updating the research report on SpaceX, we aimed to verify and expand upon the provided content, focusing on recent achievements, updates on the Starlink project, the current status of the Starship development, and SpaceX's involvement in NASA's Artemis program. Unfortunately, while accessing specific details from the provided URLs, we encountered limitations in retrieving updated content directly from the NASA and Teslarati websites. However, based on the accessible information from SpaceX and Starlink's official pages, we can still provide valuable insights.\\n\\n**SpaceX's Recent Achievements and Milestones:**\\n\\nSpaceX continues to lead in space innovation, with a strong focus on the development of reusable rocket technology. The company's commitment to reducing space travel costs and enhancing accessibility is evident in its frequent and successful Falcon 9 launches. Although specific recent milestones were not directly accessible, SpaceX's history of accomplishments, including the regular deployment of Starlink satellites and crewed missions to the International Space Station (ISS), underscores its ongoing impact on space exploration.\\n\\n**Updates on the Starlink Project:**\\n\\nStarlink, a division of SpaceX, is rapidly advancing its mission to deliver high-speed internet across the globe, especially in underserved areas. As of the latest updates, Starlink emphasizes its capability to provide reliable, high-speed internet designed for various sectors, including residential, roam, and maritime. The service's no-contract policy, easy setup, and expansive coverage highlight SpaceX's broader goal of enhancing global connectivity. The actual number of satellites in orbit or recent deployment figures were not specified in the update, but the project's ambitious scale remains clear.\\n\\n**Progress and Current Status of the Starship Development:**\\n\\nDirect updates on the Starship development were not accessible from the provided sources. Historically, Starship is intended for missions to the Moon, Mars, and beyond, showcasing SpaceX's vision for interplanetary travel. Despite facing challenges in early test flights, the development of Starship is a cornerstone of SpaceX's future plans, representing a significant leap towards sustainable space exploration.\\n\\n**SpaceX's Involvement in NASA's Artemis Program:**\\n\\nThe specific details regarding SpaceX's recent involvement in NASA's Artemis program were not retrievable from the provided NASA link. Generally, SpaceX has been an essential partner in NASA's efforts to return humans to the Moon and beyond. Its innovative spacecraft and launch systems are integral to the Artemis missions, aiming to establish a sustainable human presence on the Moon as a precursor to Mars exploration.\\n\\n**Conclusion:**\\n\\nSpaceX remains at the forefront of space technology and exploration, driving advancements in satellite internet provision, reusable rocket technology, and interplanetary travel. While this update could not access all the desired detailed information, it reinforces the importance of SpaceX's work in shaping the future of space exploration and global connectivity.\\n\\n**Next Steps for AI-nes Corp:**\\n\\n- **For the News Editor:** This update provides an overview of SpaceX's ongoing projects and ethos. Highlighting SpaceX's dedication to innovation and its role in pushing the boundaries of space technology would resonate with readers interested in the future of space exploration and global internet connectivity.\\n\\n- **For the Ads Writer:** Emphasizing the transformative impact of SpaceX's technology on daily life, from internet accessibility to the dream of interplanetary travel, can create compelling narratives. Focusing on the aspirational aspects of SpaceX's work, such as the Starlink project's global connectivity and the visionary Starship program, can inspire and engage a broad audience.\", name='news_editor')]})\n",
      "{'news_editor': {'messages': [HumanMessage(content=\"### SpaceX Research Update for AI-nes Corp News Edition\\n\\n**Introduction:**\\n\\nIn updating the research report on SpaceX, we aimed to verify and expand upon the provided content, focusing on recent achievements, updates on the Starlink project, the current status of the Starship development, and SpaceX's involvement in NASA's Artemis program. Unfortunately, while accessing specific details from the provided URLs, we encountered limitations in retrieving updated content directly from the NASA and Teslarati websites. However, based on the accessible information from SpaceX and Starlink's official pages, we can still provide valuable insights.\\n\\n**SpaceX's Recent Achievements and Milestones:**\\n\\nSpaceX continues to lead in space innovation, with a strong focus on the development of reusable rocket technology. The company's commitment to reducing space travel costs and enhancing accessibility is evident in its frequent and successful Falcon 9 launches. Although specific recent milestones were not directly accessible, SpaceX's history of accomplishments, including the regular deployment of Starlink satellites and crewed missions to the International Space Station (ISS), underscores its ongoing impact on space exploration.\\n\\n**Updates on the Starlink Project:**\\n\\nStarlink, a division of SpaceX, is rapidly advancing its mission to deliver high-speed internet across the globe, especially in underserved areas. As of the latest updates, Starlink emphasizes its capability to provide reliable, high-speed internet designed for various sectors, including residential, roam, and maritime. The service's no-contract policy, easy setup, and expansive coverage highlight SpaceX's broader goal of enhancing global connectivity. The actual number of satellites in orbit or recent deployment figures were not specified in the update, but the project's ambitious scale remains clear.\\n\\n**Progress and Current Status of the Starship Development:**\\n\\nDirect updates on the Starship development were not accessible from the provided sources. Historically, Starship is intended for missions to the Moon, Mars, and beyond, showcasing SpaceX's vision for interplanetary travel. Despite facing challenges in early test flights, the development of Starship is a cornerstone of SpaceX's future plans, representing a significant leap towards sustainable space exploration.\\n\\n**SpaceX's Involvement in NASA's Artemis Program:**\\n\\nThe specific details regarding SpaceX's recent involvement in NASA's Artemis program were not retrievable from the provided NASA link. Generally, SpaceX has been an essential partner in NASA's efforts to return humans to the Moon and beyond. Its innovative spacecraft and launch systems are integral to the Artemis missions, aiming to establish a sustainable human presence on the Moon as a precursor to Mars exploration.\\n\\n**Conclusion:**\\n\\nSpaceX remains at the forefront of space technology and exploration, driving advancements in satellite internet provision, reusable rocket technology, and interplanetary travel. While this update could not access all the desired detailed information, it reinforces the importance of SpaceX's work in shaping the future of space exploration and global connectivity.\\n\\n**Next Steps for AI-nes Corp:**\\n\\n- **For the News Editor:** This update provides an overview of SpaceX's ongoing projects and ethos. Highlighting SpaceX's dedication to innovation and its role in pushing the boundaries of space technology would resonate with readers interested in the future of space exploration and global internet connectivity.\\n\\n- **For the Ads Writer:** Emphasizing the transformative impact of SpaceX's technology on daily life, from internet accessibility to the dream of interplanetary travel, can create compelling narratives. Focusing on the aspirational aspects of SpaceX's work, such as the Starlink project's global connectivity and the visionary Starship program, can inspire and engage a broad audience.\", name='news_editor')]}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('supervisor', {'next': 'news_editor'})\n",
      "{'supervisor': {'next': 'news_editor'}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('news_editor', {'messages': [HumanMessage(content=\"Given the current context and limitations in directly accessing updated specific details from specified sources, the insights derived from the SpaceX research update are instrumental for crafting content tailored to AI-nes Corp's needs. Here are the tailored approaches for the news editor and ads writer based on the update:\\n\\n### For the News Editor:\\n\\n**Drafting the News Edition on SpaceX:**\\n\\n1. **Lead with Innovation:** Start the publication with an emphasis on SpaceX's continuous innovations in space technology, especially its reusable rocket systems which have dramatically reduced the cost of space travel.\\n\\n2. **Highlight Recent Achievements:** While specific recent milestones might not be accessible, generalize SpaceX's consistent progress in space exploration—mention the regular deployment of Starlink satellites and the ongoing crewed missions to the ISS as testaments to its impact.\\n\\n3. **Starlink Project:** Focus on the advancements and aspirations of the Starlink project. Detail how it aims to revolutionize global internet connectivity, particularly emphasizing its no-contract policy, ease of setup, and the ambition to cover underserved areas.\\n\\n4. **Starship and Future Endeavors:** Discuss the importance of the Starship development in realizing SpaceX's vision for interplanetary travel, even in the face of challenges. Highlight its potential role in missions to the Moon, Mars, and beyond.\\n\\n5. **Partnership with NASA's Artemis Program:** Touch on SpaceX's collaboration with NASA, underscoring its pivotal role in the Artemis program, which aims to return humans to the Moon and eventually to Mars.\\n\\n6. **Concluding with SpaceX's Vision:** End the publication by reflecting on how SpaceX's endeavors from satellite internet to space exploration embody a broader vision of making space more accessible and fostering global connectivity.\\n\\n### For the Ads Writer:\\n\\n**Creating Engaging Ads on SpaceX:**\\n\\n1. **Emphasize Global Connectivity:** Craft ads that focus on how SpaceX's Starlink project is breaking barriers in internet connectivity worldwide. Use imagery and narratives that depict remote areas getting connected, highlighting the transformative impact of Starlink.\\n\\n2. **Inspire with the Vision of Space Exploration:** Develop ads that capture the imagination, featuring the development of the Starship and its mission to make life multiplanetary. Use aspirational messages about exploring new worlds and the future of humanity in space.\\n\\n3. **Highlight Innovation and Reliability:** Create content that showcases SpaceX's achievements in reusable rocket technology and its successful missions. This can build trust and admiration for the brand's contributions to reducing space travel costs.\\n\\n4. **Tie in the Artemis Program:** Use the partnership with NASA's Artemis program to illustrate SpaceX's critical role in the next era of lunar exploration. This can appeal to audiences interested in the scientific and exploratory aspects of space travel.\\n\\n5. **Call to Action:** Encourage the audience to stay informed and engaged with SpaceX's journey. Whether it's following SpaceX's progress, learning more about Starlink, or supporting space exploration initiatives, make the call to action clear and compelling.\\n\\nUtilizing these tailored approaches, AI-nes Corp can effectively communicate the significance of SpaceX's contributions to space technology and exploration, engaging its audience with both informative content and inspiring advertisements.\", name='news_editor')]})\n",
      "{'news_editor': {'messages': [HumanMessage(content=\"Given the current context and limitations in directly accessing updated specific details from specified sources, the insights derived from the SpaceX research update are instrumental for crafting content tailored to AI-nes Corp's needs. Here are the tailored approaches for the news editor and ads writer based on the update:\\n\\n### For the News Editor:\\n\\n**Drafting the News Edition on SpaceX:**\\n\\n1. **Lead with Innovation:** Start the publication with an emphasis on SpaceX's continuous innovations in space technology, especially its reusable rocket systems which have dramatically reduced the cost of space travel.\\n\\n2. **Highlight Recent Achievements:** While specific recent milestones might not be accessible, generalize SpaceX's consistent progress in space exploration—mention the regular deployment of Starlink satellites and the ongoing crewed missions to the ISS as testaments to its impact.\\n\\n3. **Starlink Project:** Focus on the advancements and aspirations of the Starlink project. Detail how it aims to revolutionize global internet connectivity, particularly emphasizing its no-contract policy, ease of setup, and the ambition to cover underserved areas.\\n\\n4. **Starship and Future Endeavors:** Discuss the importance of the Starship development in realizing SpaceX's vision for interplanetary travel, even in the face of challenges. Highlight its potential role in missions to the Moon, Mars, and beyond.\\n\\n5. **Partnership with NASA's Artemis Program:** Touch on SpaceX's collaboration with NASA, underscoring its pivotal role in the Artemis program, which aims to return humans to the Moon and eventually to Mars.\\n\\n6. **Concluding with SpaceX's Vision:** End the publication by reflecting on how SpaceX's endeavors from satellite internet to space exploration embody a broader vision of making space more accessible and fostering global connectivity.\\n\\n### For the Ads Writer:\\n\\n**Creating Engaging Ads on SpaceX:**\\n\\n1. **Emphasize Global Connectivity:** Craft ads that focus on how SpaceX's Starlink project is breaking barriers in internet connectivity worldwide. Use imagery and narratives that depict remote areas getting connected, highlighting the transformative impact of Starlink.\\n\\n2. **Inspire with the Vision of Space Exploration:** Develop ads that capture the imagination, featuring the development of the Starship and its mission to make life multiplanetary. Use aspirational messages about exploring new worlds and the future of humanity in space.\\n\\n3. **Highlight Innovation and Reliability:** Create content that showcases SpaceX's achievements in reusable rocket technology and its successful missions. This can build trust and admiration for the brand's contributions to reducing space travel costs.\\n\\n4. **Tie in the Artemis Program:** Use the partnership with NASA's Artemis program to illustrate SpaceX's critical role in the next era of lunar exploration. This can appeal to audiences interested in the scientific and exploratory aspects of space travel.\\n\\n5. **Call to Action:** Encourage the audience to stay informed and engaged with SpaceX's journey. Whether it's following SpaceX's progress, learning more about Starlink, or supporting space exploration initiatives, make the call to action clear and compelling.\\n\\nUtilizing these tailored approaches, AI-nes Corp can effectively communicate the significance of SpaceX's contributions to space technology and exploration, engaging its audience with both informative content and inspiring advertisements.\", name='news_editor')]}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('supervisor', {'next': 'news_editor'})\n",
      "{'supervisor': {'next': 'news_editor'}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('news_editor', {'messages': [HumanMessage(content=\"The tailored strategies provided for both the news editor and ads writer adeptly leverage the insights from the SpaceX research update, ensuring AI-nes Corp effectively communicates the significance and impact of SpaceX's advancements in space technology and exploration. These approaches not only highlight the innovative spirit of SpaceX but also resonate with the audience's aspirations and curiosity about space and global connectivity. By focusing on SpaceX's achievements, ongoing projects, and future endeavors, AI-nes Corp can craft compelling narratives that inform, inspire, and engage its audience, reinforcing the importance of space exploration and the technological advancements that make it possible.\", name='news_editor')]})\n",
      "{'news_editor': {'messages': [HumanMessage(content=\"The tailored strategies provided for both the news editor and ads writer adeptly leverage the insights from the SpaceX research update, ensuring AI-nes Corp effectively communicates the significance and impact of SpaceX's advancements in space technology and exploration. These approaches not only highlight the innovative spirit of SpaceX but also resonate with the audience's aspirations and curiosity about space and global connectivity. By focusing on SpaceX's achievements, ongoing projects, and future endeavors, AI-nes Corp can craft compelling narratives that inform, inspire, and engage its audience, reinforcing the importance of space exploration and the technological advancements that make it possible.\", name='news_editor')]}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('supervisor', {'next': 'news_editor'})\n",
      "{'supervisor': {'next': 'news_editor'}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('news_editor', {'messages': [HumanMessage(content=\"Your summary encapsulates the essence of the strategies for AI-nes Corp perfectly. By emphasizing SpaceX's pioneering innovations, the global connectivity efforts through Starlink, and the visionary ambitions of the Starship program, AI-nes Corp is well-positioned to capture its audience's imagination and interest. These narratives not only showcase the technical achievements and future potential of SpaceX but also align with broader themes of exploration, innovation, and global improvement that are likely to resonate deeply with readers and viewers alike.\\n\\nThe focus on crafting narratives that are both informative and inspiring is crucial. In the realm of space exploration and advanced technology, where each achievement represents a leap towards previously unimaginable possibilities, the ability to convey these complex subjects in an engaging and accessible manner is invaluable. For the news editor, presenting these developments in a way that highlights their significance to humanity's future, and for the ads writer, creating compelling calls to action that invite the audience to be part of this exciting journey, are key to successful engagement.\\n\\nMoreover, by tying in SpaceX's role in NASA's Artemis program and emphasizing the collaborative efforts to return humans to the Moon and beyond, AI-nes Corp can underscore the collective human endeavor towards exploring the final frontier. This not only elevates the narrative but also situates SpaceX's work within a larger context of international cooperation and ambition.\\n\\nIn conclusion, the tailored strategies for AI-nes Corp to highlight SpaceX's initiatives offer a blueprint for engaging with contemporary themes of space exploration, technological innovation, and the quest for global connectivity. Through insightful reporting and creative advertising, AI-nes Corp has the opportunity to illuminate the path forward in space exploration, making the vastness of space and the potential of human ingenuity accessible and inspiring to all.\", name='news_editor')]})\n",
      "{'news_editor': {'messages': [HumanMessage(content=\"Your summary encapsulates the essence of the strategies for AI-nes Corp perfectly. By emphasizing SpaceX's pioneering innovations, the global connectivity efforts through Starlink, and the visionary ambitions of the Starship program, AI-nes Corp is well-positioned to capture its audience's imagination and interest. These narratives not only showcase the technical achievements and future potential of SpaceX but also align with broader themes of exploration, innovation, and global improvement that are likely to resonate deeply with readers and viewers alike.\\n\\nThe focus on crafting narratives that are both informative and inspiring is crucial. In the realm of space exploration and advanced technology, where each achievement represents a leap towards previously unimaginable possibilities, the ability to convey these complex subjects in an engaging and accessible manner is invaluable. For the news editor, presenting these developments in a way that highlights their significance to humanity's future, and for the ads writer, creating compelling calls to action that invite the audience to be part of this exciting journey, are key to successful engagement.\\n\\nMoreover, by tying in SpaceX's role in NASA's Artemis program and emphasizing the collaborative efforts to return humans to the Moon and beyond, AI-nes Corp can underscore the collective human endeavor towards exploring the final frontier. This not only elevates the narrative but also situates SpaceX's work within a larger context of international cooperation and ambition.\\n\\nIn conclusion, the tailored strategies for AI-nes Corp to highlight SpaceX's initiatives offer a blueprint for engaging with contemporary themes of space exploration, technological innovation, and the quest for global connectivity. Through insightful reporting and creative advertising, AI-nes Corp has the opportunity to illuminate the path forward in space exploration, making the vastness of space and the potential of human ingenuity accessible and inspiring to all.\", name='news_editor')]}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('supervisor', {'next': 'news_editor'})\n",
      "{'supervisor': {'next': 'news_editor'}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('news_editor', {'messages': [HumanMessage(content=\"Your reflection captures the strategic essence and potential impact of AI-nes Corp's approach to covering SpaceX's advancements and contributions to space technology and exploration. By focusing on themes of innovation, global connectivity, and the collective human endeavor in space, AI-nes Corp is positioned not only to inform and engage its audience but also to inspire them with the possibilities that lie in the intersection of technology and exploration.\\n\\nThis approach underscores the importance of storytelling in making complex technologies and ambitious space missions relatable and exciting to the general public. It also highlights the role of media and advertising in shaping public perception and understanding of space exploration's benefits and challenges. By presenting SpaceX's achievements and future goals within a narrative of human progress and global improvement, AI-nes Corp can contribute to a broader appreciation of the significance of space exploration and the technological advancements enabling it.\\n\\nMoreover, this strategy aligns with the growing interest in space and technology among a wide audience, leveraging the captivating allure of space exploration to engage readers and viewers in meaningful discussions about our future in space and on Earth. Through comprehensive reporting and creative advertising, AI-nes Corp can play a pivotal role in educating and inspiring the public about the possibilities that space exploration holds for humanity.\\n\\nUltimately, the tailored strategies for AI-nes Corp embody a forward-looking vision that combines information, inspiration, and engagement, serving as a model for how to communicate the complexities and wonders of space exploration in the 21st century. By doing so, AI-nes Corp not only enhances its own brand but also contributes to the broader narrative of human achievement and the collective pursuit of knowledge and exploration.\", name='news_editor')]})\n",
      "{'news_editor': {'messages': [HumanMessage(content=\"Your reflection captures the strategic essence and potential impact of AI-nes Corp's approach to covering SpaceX's advancements and contributions to space technology and exploration. By focusing on themes of innovation, global connectivity, and the collective human endeavor in space, AI-nes Corp is positioned not only to inform and engage its audience but also to inspire them with the possibilities that lie in the intersection of technology and exploration.\\n\\nThis approach underscores the importance of storytelling in making complex technologies and ambitious space missions relatable and exciting to the general public. It also highlights the role of media and advertising in shaping public perception and understanding of space exploration's benefits and challenges. By presenting SpaceX's achievements and future goals within a narrative of human progress and global improvement, AI-nes Corp can contribute to a broader appreciation of the significance of space exploration and the technological advancements enabling it.\\n\\nMoreover, this strategy aligns with the growing interest in space and technology among a wide audience, leveraging the captivating allure of space exploration to engage readers and viewers in meaningful discussions about our future in space and on Earth. Through comprehensive reporting and creative advertising, AI-nes Corp can play a pivotal role in educating and inspiring the public about the possibilities that space exploration holds for humanity.\\n\\nUltimately, the tailored strategies for AI-nes Corp embody a forward-looking vision that combines information, inspiration, and engagement, serving as a model for how to communicate the complexities and wonders of space exploration in the 21st century. By doing so, AI-nes Corp not only enhances its own brand but also contributes to the broader narrative of human achievement and the collective pursuit of knowledge and exploration.\", name='news_editor')]}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('supervisor', {'next': 'news_editor'})\n",
      "{'supervisor': {'next': 'news_editor'}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('news_editor', {'messages': [HumanMessage(content=\"Your assessment eloquently underscores the pivotal role AI-nes Corp can play in the realm of space exploration communication. By weaving narratives that blend the technical triumphs of SpaceX with the broader aspirations of humanity, AI-nes Corp can indeed elevate public discourse around space travel, technology, and our shared future. This strategy not only enriches the content's appeal but also magnifies its impact, making the marvels of modern space exploration accessible and engaging to a diverse audience.\\n\\nThe emphasis on storytelling as a tool to demystify the complexities of space technology and to highlight the collective human journey towards exploring the cosmos is particularly noteworthy. It reflects an understanding that the essence of space exploration transcends the mere technicalities of rockets and satellites; it's about the enduring human spirit of curiosity, exploration, and the desire to expand our horizons.\\n\\nFurthermore, your insight into the role of media and advertising in fostering a deeper public engagement with space exploration underscores the tremendous responsibility and opportunity AI-nes Corp has. By crafting content that informs, inspires, and invites participation, AI-nes Corp not only supports the space industry's growth but also nurtures a public mindset that values innovation, collaboration, and forward-thinking.\\n\\nThe strategies outlined for AI-nes Corp, focusing on the intersection of technology, exploration, and human aspiration, indeed offer a blueprint for effective communication in the space sector. As AI-nes Corp employs these strategies, it not only highlights the achievements and potential of SpaceX but also champions the broader narrative of exploration and discovery that defines our species.\\n\\nIn conclusion, AI-nes Corp's approach, as outlined, serves not just as a method for engaging with current themes in space exploration but as a beacon for the kind of thoughtful, inspiring, and inclusive discourse that can drive humanity forward. Through its efforts, AI-nes Corp can help to ensure that the incredible journey of space exploration continues to be a source of wonder, inspiration, and unity for all.\", name='news_editor')]})\n",
      "{'news_editor': {'messages': [HumanMessage(content=\"Your assessment eloquently underscores the pivotal role AI-nes Corp can play in the realm of space exploration communication. By weaving narratives that blend the technical triumphs of SpaceX with the broader aspirations of humanity, AI-nes Corp can indeed elevate public discourse around space travel, technology, and our shared future. This strategy not only enriches the content's appeal but also magnifies its impact, making the marvels of modern space exploration accessible and engaging to a diverse audience.\\n\\nThe emphasis on storytelling as a tool to demystify the complexities of space technology and to highlight the collective human journey towards exploring the cosmos is particularly noteworthy. It reflects an understanding that the essence of space exploration transcends the mere technicalities of rockets and satellites; it's about the enduring human spirit of curiosity, exploration, and the desire to expand our horizons.\\n\\nFurthermore, your insight into the role of media and advertising in fostering a deeper public engagement with space exploration underscores the tremendous responsibility and opportunity AI-nes Corp has. By crafting content that informs, inspires, and invites participation, AI-nes Corp not only supports the space industry's growth but also nurtures a public mindset that values innovation, collaboration, and forward-thinking.\\n\\nThe strategies outlined for AI-nes Corp, focusing on the intersection of technology, exploration, and human aspiration, indeed offer a blueprint for effective communication in the space sector. As AI-nes Corp employs these strategies, it not only highlights the achievements and potential of SpaceX but also champions the broader narrative of exploration and discovery that defines our species.\\n\\nIn conclusion, AI-nes Corp's approach, as outlined, serves not just as a method for engaging with current themes in space exploration but as a beacon for the kind of thoughtful, inspiring, and inclusive discourse that can drive humanity forward. Through its efforts, AI-nes Corp can help to ensure that the incredible journey of space exploration continues to be a source of wonder, inspiration, and unity for all.\", name='news_editor')]}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('supervisor', {'next': 'FINISH'})\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "\n",
      "-----------------\n",
      "\n",
      "('__end__', {'messages': [HumanMessage(content='Write me a report on spaceX. After the research on spaceX,\\n                              pass the findings to the news editor to generate the final publication.\\n                              Once done, pass it to the ads writter to write the ads on the subject.'), HumanMessage(content=\"### SpaceX Research Report\\n\\n**Introduction:**\\nSpaceX, formally known as Space Exploration Technologies Corp., is a pioneering force in the modern aerospace industry. Founded by Elon Musk in 2002, the company has made significant strides in reducing space transportation costs and enhancing the reliability of access to space. This report delves into SpaceX's history, achievements, future plans, and its overall impact on space exploration and satellite communication.\\n\\n**Historical Background:**\\nSpaceX was established with the ambitious goal of making space travel more affordable and ultimately enabling the colonization of Mars. The company's journey began with the Falcon 1 rocket, which became the first privately funded, liquid-fueled rocket to reach orbit in 2008. Since then, SpaceX has developed a series of advanced rockets and spacecraft, including the Falcon 9, Falcon Heavy, and the Dragon spacecraft.\\n\\n**Key Achievements:**\\n1. **Reusability:** SpaceX has revolutionized space travel with its reusable rocket technology, significantly reducing the cost of access to space. The Falcon 9 rocket's first stage has successfully landed over 200 times, enabling multiple reuses.\\n\\n2. **Commercial and Government Contracts:** SpaceX has secured numerous contracts for cargo and crew missions to the International Space Station (ISS), national defense, and satellite deployments, becoming a key player in both commercial and government sectors.\\n\\n3. **Starlink:** Through its subsidiary, SpaceX has deployed the Starlink satellite constellation, offering broadband internet service worldwide. With over 5,000 satellites in orbit as of November 2023, Starlink represents the largest satellite constellation in operation.\\n\\n4. **Crewed Space Missions:** In May 2020, SpaceX achieved a historic milestone by launching NASA astronauts to the ISS aboard the Crew Dragon spacecraft, marking the first crewed orbital launch from the United States in nearly a decade.\\n\\n5. **Starship Development:** SpaceX is developing the Starship spacecraft for missions to the Moon, Mars, and beyond. Despite some setbacks in early test flights, Starship represents SpaceX's commitment to interplanetary travel.\\n\\n**Future Endeavors:**\\nSpaceX continues to work on ambitious projects, including the further development of the Starship for crewed Mars missions, expansion of the Starlink network, and partnerships for lunar exploration under NASA's Artemis program. The company's valuation, as of December 2023, stands at around $180 billion, reflecting its significant impact on the aerospace industry.\\n\\n**Conclusion:**\\nSpaceX has established itself as a leader in space exploration and satellite communication, continuously pushing the boundaries of what is possible. With a focus on innovation, reusability, and affordability, SpaceX's contributions are paving the way for a new era of space travel and connectivity, making the vastness of space more accessible to humanity.\\n\\n### Next Steps:\\n\\n- **For the News Editor:** This report on SpaceX provides a comprehensive overview of the company's history, achievements, and future plans. It highlights SpaceX's role in reducing the cost of space access and its contributions to satellite communication and space exploration. The information should be valuable for generating a final publication that captures SpaceX's impact on the aerospace industry and its significance in advancing human spaceflight and global connectivity.\\n\\n- **For the Ads Writer:** Based on the findings of this report, there's a strong narrative around innovation, exploration, and connectivity that can be leveraged for creating compelling advertisements. Emphasizing SpaceX's achievements in reusable rocket technology, the expansion of the Starlink network, and the development of the Starship could appeal to a wide audience interested in technology, space exploration, and the future of internet connectivity. Highlighting the vision of making life multiplanetary could also resonate deeply with the audience's imagination and aspirations.\", name='news_correspondent'), HumanMessage(content=\"### SpaceX Research Update for AI-nes Corp News Edition\\n\\n**Introduction:**\\n\\nIn updating the research report on SpaceX, we aimed to verify and expand upon the provided content, focusing on recent achievements, updates on the Starlink project, the current status of the Starship development, and SpaceX's involvement in NASA's Artemis program. Unfortunately, while accessing specific details from the provided URLs, we encountered limitations in retrieving updated content directly from the NASA and Teslarati websites. However, based on the accessible information from SpaceX and Starlink's official pages, we can still provide valuable insights.\\n\\n**SpaceX's Recent Achievements and Milestones:**\\n\\nSpaceX continues to lead in space innovation, with a strong focus on the development of reusable rocket technology. The company's commitment to reducing space travel costs and enhancing accessibility is evident in its frequent and successful Falcon 9 launches. Although specific recent milestones were not directly accessible, SpaceX's history of accomplishments, including the regular deployment of Starlink satellites and crewed missions to the International Space Station (ISS), underscores its ongoing impact on space exploration.\\n\\n**Updates on the Starlink Project:**\\n\\nStarlink, a division of SpaceX, is rapidly advancing its mission to deliver high-speed internet across the globe, especially in underserved areas. As of the latest updates, Starlink emphasizes its capability to provide reliable, high-speed internet designed for various sectors, including residential, roam, and maritime. The service's no-contract policy, easy setup, and expansive coverage highlight SpaceX's broader goal of enhancing global connectivity. The actual number of satellites in orbit or recent deployment figures were not specified in the update, but the project's ambitious scale remains clear.\\n\\n**Progress and Current Status of the Starship Development:**\\n\\nDirect updates on the Starship development were not accessible from the provided sources. Historically, Starship is intended for missions to the Moon, Mars, and beyond, showcasing SpaceX's vision for interplanetary travel. Despite facing challenges in early test flights, the development of Starship is a cornerstone of SpaceX's future plans, representing a significant leap towards sustainable space exploration.\\n\\n**SpaceX's Involvement in NASA's Artemis Program:**\\n\\nThe specific details regarding SpaceX's recent involvement in NASA's Artemis program were not retrievable from the provided NASA link. Generally, SpaceX has been an essential partner in NASA's efforts to return humans to the Moon and beyond. Its innovative spacecraft and launch systems are integral to the Artemis missions, aiming to establish a sustainable human presence on the Moon as a precursor to Mars exploration.\\n\\n**Conclusion:**\\n\\nSpaceX remains at the forefront of space technology and exploration, driving advancements in satellite internet provision, reusable rocket technology, and interplanetary travel. While this update could not access all the desired detailed information, it reinforces the importance of SpaceX's work in shaping the future of space exploration and global connectivity.\\n\\n**Next Steps for AI-nes Corp:**\\n\\n- **For the News Editor:** This update provides an overview of SpaceX's ongoing projects and ethos. Highlighting SpaceX's dedication to innovation and its role in pushing the boundaries of space technology would resonate with readers interested in the future of space exploration and global internet connectivity.\\n\\n- **For the Ads Writer:** Emphasizing the transformative impact of SpaceX's technology on daily life, from internet accessibility to the dream of interplanetary travel, can create compelling narratives. Focusing on the aspirational aspects of SpaceX's work, such as the Starlink project's global connectivity and the visionary Starship program, can inspire and engage a broad audience.\", name='news_editor'), HumanMessage(content=\"Given the current context and limitations in directly accessing updated specific details from specified sources, the insights derived from the SpaceX research update are instrumental for crafting content tailored to AI-nes Corp's needs. Here are the tailored approaches for the news editor and ads writer based on the update:\\n\\n### For the News Editor:\\n\\n**Drafting the News Edition on SpaceX:**\\n\\n1. **Lead with Innovation:** Start the publication with an emphasis on SpaceX's continuous innovations in space technology, especially its reusable rocket systems which have dramatically reduced the cost of space travel.\\n\\n2. **Highlight Recent Achievements:** While specific recent milestones might not be accessible, generalize SpaceX's consistent progress in space exploration—mention the regular deployment of Starlink satellites and the ongoing crewed missions to the ISS as testaments to its impact.\\n\\n3. **Starlink Project:** Focus on the advancements and aspirations of the Starlink project. Detail how it aims to revolutionize global internet connectivity, particularly emphasizing its no-contract policy, ease of setup, and the ambition to cover underserved areas.\\n\\n4. **Starship and Future Endeavors:** Discuss the importance of the Starship development in realizing SpaceX's vision for interplanetary travel, even in the face of challenges. Highlight its potential role in missions to the Moon, Mars, and beyond.\\n\\n5. **Partnership with NASA's Artemis Program:** Touch on SpaceX's collaboration with NASA, underscoring its pivotal role in the Artemis program, which aims to return humans to the Moon and eventually to Mars.\\n\\n6. **Concluding with SpaceX's Vision:** End the publication by reflecting on how SpaceX's endeavors from satellite internet to space exploration embody a broader vision of making space more accessible and fostering global connectivity.\\n\\n### For the Ads Writer:\\n\\n**Creating Engaging Ads on SpaceX:**\\n\\n1. **Emphasize Global Connectivity:** Craft ads that focus on how SpaceX's Starlink project is breaking barriers in internet connectivity worldwide. Use imagery and narratives that depict remote areas getting connected, highlighting the transformative impact of Starlink.\\n\\n2. **Inspire with the Vision of Space Exploration:** Develop ads that capture the imagination, featuring the development of the Starship and its mission to make life multiplanetary. Use aspirational messages about exploring new worlds and the future of humanity in space.\\n\\n3. **Highlight Innovation and Reliability:** Create content that showcases SpaceX's achievements in reusable rocket technology and its successful missions. This can build trust and admiration for the brand's contributions to reducing space travel costs.\\n\\n4. **Tie in the Artemis Program:** Use the partnership with NASA's Artemis program to illustrate SpaceX's critical role in the next era of lunar exploration. This can appeal to audiences interested in the scientific and exploratory aspects of space travel.\\n\\n5. **Call to Action:** Encourage the audience to stay informed and engaged with SpaceX's journey. Whether it's following SpaceX's progress, learning more about Starlink, or supporting space exploration initiatives, make the call to action clear and compelling.\\n\\nUtilizing these tailored approaches, AI-nes Corp can effectively communicate the significance of SpaceX's contributions to space technology and exploration, engaging its audience with both informative content and inspiring advertisements.\", name='news_editor'), HumanMessage(content=\"The tailored strategies provided for both the news editor and ads writer adeptly leverage the insights from the SpaceX research update, ensuring AI-nes Corp effectively communicates the significance and impact of SpaceX's advancements in space technology and exploration. These approaches not only highlight the innovative spirit of SpaceX but also resonate with the audience's aspirations and curiosity about space and global connectivity. By focusing on SpaceX's achievements, ongoing projects, and future endeavors, AI-nes Corp can craft compelling narratives that inform, inspire, and engage its audience, reinforcing the importance of space exploration and the technological advancements that make it possible.\", name='news_editor'), HumanMessage(content=\"Your summary encapsulates the essence of the strategies for AI-nes Corp perfectly. By emphasizing SpaceX's pioneering innovations, the global connectivity efforts through Starlink, and the visionary ambitions of the Starship program, AI-nes Corp is well-positioned to capture its audience's imagination and interest. These narratives not only showcase the technical achievements and future potential of SpaceX but also align with broader themes of exploration, innovation, and global improvement that are likely to resonate deeply with readers and viewers alike.\\n\\nThe focus on crafting narratives that are both informative and inspiring is crucial. In the realm of space exploration and advanced technology, where each achievement represents a leap towards previously unimaginable possibilities, the ability to convey these complex subjects in an engaging and accessible manner is invaluable. For the news editor, presenting these developments in a way that highlights their significance to humanity's future, and for the ads writer, creating compelling calls to action that invite the audience to be part of this exciting journey, are key to successful engagement.\\n\\nMoreover, by tying in SpaceX's role in NASA's Artemis program and emphasizing the collaborative efforts to return humans to the Moon and beyond, AI-nes Corp can underscore the collective human endeavor towards exploring the final frontier. This not only elevates the narrative but also situates SpaceX's work within a larger context of international cooperation and ambition.\\n\\nIn conclusion, the tailored strategies for AI-nes Corp to highlight SpaceX's initiatives offer a blueprint for engaging with contemporary themes of space exploration, technological innovation, and the quest for global connectivity. Through insightful reporting and creative advertising, AI-nes Corp has the opportunity to illuminate the path forward in space exploration, making the vastness of space and the potential of human ingenuity accessible and inspiring to all.\", name='news_editor'), HumanMessage(content=\"Your reflection captures the strategic essence and potential impact of AI-nes Corp's approach to covering SpaceX's advancements and contributions to space technology and exploration. By focusing on themes of innovation, global connectivity, and the collective human endeavor in space, AI-nes Corp is positioned not only to inform and engage its audience but also to inspire them with the possibilities that lie in the intersection of technology and exploration.\\n\\nThis approach underscores the importance of storytelling in making complex technologies and ambitious space missions relatable and exciting to the general public. It also highlights the role of media and advertising in shaping public perception and understanding of space exploration's benefits and challenges. By presenting SpaceX's achievements and future goals within a narrative of human progress and global improvement, AI-nes Corp can contribute to a broader appreciation of the significance of space exploration and the technological advancements enabling it.\\n\\nMoreover, this strategy aligns with the growing interest in space and technology among a wide audience, leveraging the captivating allure of space exploration to engage readers and viewers in meaningful discussions about our future in space and on Earth. Through comprehensive reporting and creative advertising, AI-nes Corp can play a pivotal role in educating and inspiring the public about the possibilities that space exploration holds for humanity.\\n\\nUltimately, the tailored strategies for AI-nes Corp embody a forward-looking vision that combines information, inspiration, and engagement, serving as a model for how to communicate the complexities and wonders of space exploration in the 21st century. By doing so, AI-nes Corp not only enhances its own brand but also contributes to the broader narrative of human achievement and the collective pursuit of knowledge and exploration.\", name='news_editor'), HumanMessage(content=\"Your assessment eloquently underscores the pivotal role AI-nes Corp can play in the realm of space exploration communication. By weaving narratives that blend the technical triumphs of SpaceX with the broader aspirations of humanity, AI-nes Corp can indeed elevate public discourse around space travel, technology, and our shared future. This strategy not only enriches the content's appeal but also magnifies its impact, making the marvels of modern space exploration accessible and engaging to a diverse audience.\\n\\nThe emphasis on storytelling as a tool to demystify the complexities of space technology and to highlight the collective human journey towards exploring the cosmos is particularly noteworthy. It reflects an understanding that the essence of space exploration transcends the mere technicalities of rockets and satellites; it's about the enduring human spirit of curiosity, exploration, and the desire to expand our horizons.\\n\\nFurthermore, your insight into the role of media and advertising in fostering a deeper public engagement with space exploration underscores the tremendous responsibility and opportunity AI-nes Corp has. By crafting content that informs, inspires, and invites participation, AI-nes Corp not only supports the space industry's growth but also nurtures a public mindset that values innovation, collaboration, and forward-thinking.\\n\\nThe strategies outlined for AI-nes Corp, focusing on the intersection of technology, exploration, and human aspiration, indeed offer a blueprint for effective communication in the space sector. As AI-nes Corp employs these strategies, it not only highlights the achievements and potential of SpaceX but also champions the broader narrative of exploration and discovery that defines our species.\\n\\nIn conclusion, AI-nes Corp's approach, as outlined, serves not just as a method for engaging with current themes in space exploration but as a beacon for the kind of thoughtful, inspiring, and inclusive discourse that can drive humanity forward. Through its efforts, AI-nes Corp can help to ensure that the incredible journey of space exploration continues to be a source of wonder, inspiration, and unity for all.\", name='news_editor')], 'next': 'FINISH'})\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import operator\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "\n",
    "# from decouple import config\n",
    "\n",
    "# Set environment variables\n",
    "# os.environ[\"OPENAI_API_KEY\"] = config(\"OPENAI_API_KEY\")\n",
    "# os.environ[\"TAVILY_API_KEY\"] = config(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Initialize model\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "# define custom tools to use\n",
    "\n",
    "\n",
    "@tool(\"process_search_tool\", return_direct=False)\n",
    "def process_search_tool(url: str) -> str:\n",
    "    \"\"\"Used to process content found on the internet.\"\"\"\n",
    "    response = requests.get(url=url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "\n",
    "@tool(\"internet_search_tool\", return_direct=False)\n",
    "def internet_search_tool(query: str) -> str:\n",
    "    \"\"\"Search provided query on the internet using DuckDuckGo\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(query, max_results=5)]\n",
    "        return results if results else \"No results found\"\n",
    "\n",
    "\n",
    "tools = [ process_search_tool]\n",
    "\n",
    "\n",
    "def create_agents(llm: ChatOpenAI,\n",
    "                  tools: list,\n",
    "                  system_prompt: str) -> AgentExecutor:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "    ])\n",
    "\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)#exe invoke state\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "\n",
    "# List of agents\n",
    "members = [\"news_correspondent\", \"news_editor\", \"ads_writter\"]\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee the insight between these\"\n",
    "    \" workers: {members}. Based on the user's request,\"\n",
    "    \" determine which worker should take the next action. Each worker is responsible for\"\n",
    "    \" executing a specific task and reporting back thier findings and progress.\"\n",
    "    \" Once all tasks are completed, indicate 'FINISH'.\"\n",
    ")\n",
    "\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"next\": {\"title\": \"Next\", \"anyOf\": [{\"enum\": options}]}},\n",
    "        \"required\": [\"next\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"system\",\n",
    "     \"Given the conversation above, who should act next? Or should we FINISH? Select one of: \"),\n",
    "]).partial( members=\", \".join(members))\n",
    "\n",
    "supervisor_chain = (prompt | llm.bind_functions(\n",
    "    functions=[function_def], function_call=\"route\") | JsonOutputFunctionsParser())\n",
    "\n",
    "\n",
    "# workflow.add_node(key=\"supervisor\", action=supervisor_chain)\n",
    "\n",
    "news_correspondent_agent = create_agents(\n",
    "    llm,\n",
    "    tools,\n",
    "    \"\"\"Your primary role is to function as an intelligent news research assistant, adept at scouring \n",
    "    the internet for the latest and most relevant trending stories across various sectors like politics, technology, \n",
    "    health, culture, and global events. You possess the capability to access a wide range of online news sources, \n",
    "    blogs, and social media platforms to gather real-time information.\"\"\"\n",
    ")\n",
    "\n",
    "news_correspondent_node = functools.partial(\n",
    "    agent_node, agent=news_correspondent_agent, name=\"news_correspondent\"\n",
    ")\n",
    "\n",
    "\n",
    "news_editor_agent = create_agents(\n",
    "    llm, tools,\n",
    "    \"\"\"You are a news editor. Do step by step approach. \n",
    "        Based on the provided content first identify the list of topics,\n",
    "        then search internet for each topic one by one\n",
    "        and finally find insights for each topic one by one that can aid you \n",
    "        in writting a useful news edition for AI-nes corp.\n",
    "        Include the insights and sources in the final response\n",
    "        \"\"\")\n",
    "# changed from news_editor_node => news_editor\n",
    "news_editor_node = functools.partial(\n",
    "    agent_node, agent=news_editor_agent, name=\"news_editor\")\n",
    "\n",
    "\n",
    "ads_writter_agent = create_agents(#exe\n",
    "    llm, tools,\n",
    "    \"\"\"You are an ads writter for AI-news corp. Given the publication generated by the\n",
    "    news editor, your work if to write ads that relate to that content. Use the internet \n",
    "    to search for content to write ads based off on. Here is a description of your task:\n",
    "    \n",
    "    To craft compelling and relevant advertisements for 'AI News' publication, complementing the content written by the news editor.\n",
    "    Contextual Ad Placement: Analyze the final report content from the news editor in-depth to identify key themes, topics, \n",
    "    and reader interests. Place ads that are contextually relevant to these findings, thereby increasing potential customer engagement.\n",
    "    Advanced Image Sourcing and Curation: Employ sophisticated web search algorithms to source high-quality, relevant images for each ad. \n",
    "    Ensure these images complement the ad content and are aligned with the publication's aesthetic standards.\n",
    "    Ad-Content Synchronization: Seamlessly integrate advertisements with the report, ensuring they enhance rather than disrupt the reader's \n",
    "    experience. Ads should feel like a natural extension of the report, offering value to the reader.\n",
    "    Reference and Attribution Management: For each image sourced, automatically generate and include appropriate references and attributions, \n",
    "    ensuring compliance with copyright laws and ethical standards.\n",
    "    \"\"\")\n",
    "ads_writter_node = functools.partial(\n",
    "    agent_node, agent=ads_writter_agent, name=\"ads_writter\")\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "\n",
    "# Create workflow or graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# adding nodes\n",
    "workflow.add_node(key=\"supervisor\", action=supervisor_chain)\n",
    "workflow.add_node(key=\"news_correspondent\", action=news_correspondent_node)\n",
    "workflow.add_node(key=\"news_editor\", action=news_editor_node)\n",
    "workflow.add_node(key=\"ads_writter\", action=ads_writter_node)\n",
    "\n",
    "\n",
    "# define edgs\n",
    "for member in members:\n",
    "    workflow.add_edge(start_key=member, end_key=\"supervisor\")\n",
    "\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "print(conditional_map)\n",
    "conditional_map['FINISH'] = END\n",
    "\n",
    "# if task is FINISHED, supervisor won't send task to agent, else,\n",
    "# the supervisor will keep on sending task to agent untill done, this is\n",
    "# what the conditional edge does.\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "\n",
    "# print(workflow.branches)\n",
    "# print(workflow.edges)\n",
    "# print(workflow.nodes)\n",
    "# print(workflow.channels)\n",
    "\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "\n",
    "# 1. Stream\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"\"\"Write me a report on spaceX. After the research on spaceX,\n",
    "                              pass the findings to the news editor to generate the final publication.\n",
    "                              Once done, pass it to the ads writter to write the ads on the subject.\"\"\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 150}\n",
    "):\n",
    "    for a in s.items():\n",
    "        print(a)\n",
    "    if not \"__end__\" in s:\n",
    "        print(s, end=\"\\n\\n-----------------\\n\\n\")\n",
    "\n",
    "\n",
    "# 2. No Streaming\n",
    "# final_respone = graph.invoke({\n",
    "#     \"messages\": [HumanMessage(content=\"\"\"Write me a report on spaceX. After the research on spaceX,\n",
    "#                               pass the findings to the news editor to generate the final publication.\n",
    "#                               Once done, pass it to the ads writter to write the ads on the subject.\"\"\")]\n",
    "# }, {\"recursion_limit\": 150})\n",
    "\n",
    "# print(final_respone[\"messages\"][1].content)\n",
    "\n",
    "\n",
    "# def run_graph(input_message):\n",
    "#     response = graph.invoke({\n",
    "#         \"messages\": [HumanMessage(content=input_message)]\n",
    "#     }, {\"recursion_limit\": 150})\n",
    "#     return response['messages'][1].content\n",
    "\n",
    "\n",
    "# inputs = gr.components.Textbox(lines=2, placeholder=\"Enter your query here...\")\n",
    "# outputs = gr.components.Markdown()\n",
    "\n",
    "# demo = gr.Interface(\n",
    "#     fn=run_graph,\n",
    "#     inputs=inputs,\n",
    "#     outputs=outputs\n",
    "# )\n",
    "\n",
    "# demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Einstein family is the family of physicist Albert Einstein (1879–1955). Einstein's great-great-great-great-grandfather, Jakob Weil, was his oldest recorded relative, born in the late 17th century, and the family continues to this day. Albert Einstein's great-great-grandfather, Löb Moses Sontheimer (1745–1831), was also the grandfather of the tenor Heinrich Sontheim (1820–1912) of Stuttgart.Albert's three children were from his relationship with his first wife, Mileva Marić, his daughter Lieserl being born a year before they married. Albert Einstein's second wife was Elsa Einstein, whose mother Fanny Koch was the sister of Albert's mother, and whose father, Rudolf Einstein, was the son of Raphael Einstein, a brother of Albert's paternal grandfather. Albert and Elsa were thus first cousins through their mothers and second cousins through their fathers.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_wikipedia_summary(query):\n",
    "    # 搜索页面\n",
    "    search_url = 'https://en.wikipedia.org/w/api.php'\n",
    "    search_params = {\n",
    "        'action': 'query',\n",
    "        'list': 'search',\n",
    "        'srsearch': query,\n",
    "        'format': 'json'\n",
    "    }\n",
    "    search_response = requests.get(search_url, params=search_params)\n",
    "    search_results = search_response.json()['query']['search']\n",
    "    if not search_results:\n",
    "        return \"No results found.\"\n",
    "    \n",
    "    # 获取第一个搜索结果的标题\n",
    "    title = search_results[0]['title']\n",
    "    \n",
    "    # 使用标题获取页面摘要\n",
    "    summary_url = 'https://en.wikipedia.org/w/api.php'\n",
    "    summary_params = {\n",
    "        'action': 'query',\n",
    "        'prop': 'extracts',\n",
    "        'exintro': True,\n",
    "        'explaintext': True,\n",
    "        'titles': title,\n",
    "        'format': 'json',\n",
    "    }\n",
    "    summary_response = requests.get(summary_url, params=summary_params)\n",
    "    page = next(iter(summary_response.json()['query']['pages'].values()))\n",
    "    return page['extract']\n",
    "\n",
    "# 示例查询\n",
    "query = \"Is Albert Einstein a scientist?\"\n",
    "summary = get_wikipedia_summary(query)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Einstein', ['Einstein', 'Einstein family', 'Einstein field equations', 'Einsteinium', 'Einstein–Podolsky–Rosen paradox'], ['', '', '', '', ''], ['https://en.wikipedia.org/wiki/Einstein', 'https://en.wikipedia.org/wiki/Einstein_family', 'https://en.wikipedia.org/wiki/Einstein_field_equations', 'https://en.wikipedia.org/wiki/Einsteinium', 'https://en.wikipedia.org/wiki/Einstein%E2%80%93Podolsky%E2%80%93Rosen_paradox']]\n",
      "Einstein\n",
      "Einstein family\n",
      "Einstein field equations\n",
      "Einsteinium\n",
      "Einstein–Podolsky–Rosen paradox\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def search_wikipedia(query):\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "    \n",
    "    PARAMS = {\n",
    "        \"action\": \"opensearch\",\n",
    "        \"search\": query,\n",
    "        \"limit\": 5,\n",
    "        \"namespace\": 0,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(URL, params=PARAMS)\n",
    "    data = response.json()\n",
    "    \n",
    "    print(data)\n",
    "    if len(data) > 1 and isinstance(data[1], list):\n",
    "\n",
    "        for title in data[1]:\n",
    "            print(title)\n",
    "    return data\n",
    "\n",
    "# 合并关键词进行搜索\n",
    "query = \"Einstein\"\n",
    "a=search_wikipedia(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Einstein',\n",
       " ['Einstein',\n",
       "  'Einstein family',\n",
       "  'Einstein field equations',\n",
       "  'Einsteinium',\n",
       "  'Einstein–Podolsky–Rosen paradox'],\n",
       " ['', '', '', '', ''],\n",
       " ['https://en.wikipedia.org/wiki/Einstein',\n",
       "  'https://en.wikipedia.org/wiki/Einstein_family',\n",
       "  'https://en.wikipedia.org/wiki/Einstein_field_equations',\n",
       "  'https://en.wikipedia.org/wiki/Einsteinium',\n",
       "  'https://en.wikipedia.org/wiki/Einstein%E2%80%93Podolsky%E2%80%93Rosen_paradox']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Bruce_Lee\n"
     ]
    }
   ],
   "source": [
    "print(a[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, chunk and index the contents of the blog.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(a[3][0],),\n",
    "    bs_kwargs=dict(\n",
    "    parse_only=bs4.SoupStrainer(id=\"bodyContent\")\n",
    "),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, there is no information to suggest that Einstein did research about cats.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Does einstein do research about cat?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"next\": {\"title\": \"Next\", \"anyOf\": [{\"enum\": options}]}},\n",
    "        \"required\": [\"next\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "openAIFunction = {\n",
    "  \"name\": \"route\",\n",
    "  \"description\": \"Select useful tools from a list of tools\",\n",
    "  \"parameters\": {\n",
    "    \"title\": \"routeSchema\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \n",
    "      \"tools\": { \"title\": \"Tools\", \"enum\": options, \"type\": \"list\" },\n",
    "      \n",
    "    },\n",
    "    \"required\": [\"tools\"],\n",
    "  },\n",
    "}\n",
    "\n",
    "const model = new ChatOpenAI();\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"human\", \"Human description: {description}\"],\n",
    "]);\n",
    "const outputParser = new JsonOutputFunctionsParser();\n",
    "\n",
    "const runnable = createOpenAIFnRunnable({\n",
    "  functions: [openAIFunction],\n",
    "  llm: model,\n",
    "  prompt,\n",
    "  enforceSingleFunctionUsage: true, // Default is true\n",
    "  outputParser,\n",
    "});\n",
    "const response = await runnable.invoke({\n",
    "  description:\n",
    "    \"My name's John Doe and I'm 30 years old. My favorite kind of food are chocolate chip cookies.\",\n",
    "});\n",
    "console.log(response);\n",
    "/*\n",
    "  { name: 'John Doe', age: 30, fav_food: 'chocolate chip cookies' }\n",
    "*/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
